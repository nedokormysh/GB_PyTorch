{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz/N01LWvCorYBsC2wHUMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedokormysh/GB_PyTorch/blob/lesson7/GB_PyTorch_hw_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "1. Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "\n",
        "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?\n",
        "\n",
        "У кого нет возможности работать через каггл (нет верификации), то можете данные взять по ссылке: https://disk.yandex.ru/d/LV1cYS1orMyRWA"
      ],
      "metadata": {
        "id": "9_9YJ8TtZcXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys5j-FHySl8M",
        "outputId": "93124e31-4efc-4fa9-c751-80d565a6c553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 10.8 MB/s \n",
            "\u001b[?25h  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words pymorphy2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "# from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from itertools import islice\n",
        "from nltk.probability import FreqDist\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "CRc8r3W0ZzRk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "! unzip -q '/content/twitter-sentiment-analysis-hatred-speech.zip'\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "mQNh8odgaOdJ",
        "outputId": "a7bc659e-ab03-4a14-b2f7-373b36b1bc37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa8a1f97-19eb-419d-992f-eaa06a252efb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa8a1f97-19eb-419d-992f-eaa06a252efb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading twitter-sentiment-analysis-hatred-speech.zip to /content\n",
            "  0% 0.00/1.89M [00:00<?, ?B/s]\n",
            "100% 1.89M/1.89M [00:00<00:00, 203MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/train.csv')\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "7xmGO3o_aUSq",
        "outputId": "97fdc788-d30d-42fb-e219-3fe55b0a27bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31962, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06b15459-c6dc-4bd3-977b-4b7a524101c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06b15459-c6dc-4bd3-977b-4b7a524101c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06b15459-c6dc-4bd3-977b-4b7a524101c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06b15459-c6dc-4bd3-977b-4b7a524101c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test = pd.read_csv('/content/test.csv')\n",
        "# print(df_test.shape)\n",
        "# df_test.head()"
      ],
      "metadata": {
        "id": "1yLry8OhcwXo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtnaHBbldlG5",
        "outputId": "debd0767-3f52-4c2b-de3f-2ca31ce8a4fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42\n",
        "\n",
        "max_words = 1500\n",
        "max_len = 15\n",
        "num_classes = 1\n",
        "\n",
        "# Training\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "embedding_dim = 256\n",
        "out_channel = 256"
      ],
      "metadata": {
        "id": "kFz1ODj0doSv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Несбалансированность классов будем исправлять за счёт стратификации."
      ],
      "metadata": {
        "id": "Nb-MQkARz8sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val = train_test_split(df_train, \n",
        "                                  test_size=0.2, \n",
        "                                  random_state=random_state, \n",
        "                                  stratify=df_train['label'])\n",
        "\n",
        "X_train.shape, X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7HieW-jz7mA",
        "outputId": "1dcbc929-cf35-4e0b-d2cb-0aadef6c4503"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25569, 3), (6393, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка"
      ],
      "metadata": {
        "id": "KMsNMZZTd_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "sw.add('@user')\n",
        "sw.add('user')\n",
        "sw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtm2KfJ2pB7z",
        "outputId": "ac0b6c11-a9bb-44d3-bd6c-9c6d7eda8705"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@user',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " \"can't\",\n",
              " 'cannot',\n",
              " 'could',\n",
              " \"couldn't\",\n",
              " 'did',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " \"here's\",\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " \"how's\",\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"let's\",\n",
              " 'me',\n",
              " 'more',\n",
              " 'most',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'same',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that's\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " \"there's\",\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'user',\n",
              " 'very',\n",
              " 'was',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " \"what's\",\n",
              " 'when',\n",
              " \"when's\",\n",
              " 'where',\n",
              " \"where's\",\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " \"who's\",\n",
              " 'whom',\n",
              " 'why',\n",
              " \"why's\",\n",
              " 'with',\n",
              " \"won't\",\n",
              " 'would',\n",
              " \"wouldn't\",\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "puncts = set(punctuation)\n",
        "# puncts"
      ],
      "metadata": {
        "id": "eKi-OIHVzUgp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtxd7imqzZNR",
        "outputId": "c2527bae-6938-41d0-a758-074a2680feaf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    # уберем нечитаемые символы типа  ð\\x9f¤\\x97\n",
        "    txt = \"\".join([c for c in txt if ord(c) < 128])\n",
        "    txt = ''.join(char for char in txt if char not in puncts) # очистка от пунктуации\n",
        "    txt = txt.lower()\n",
        "    # преобразуем отрицания\n",
        "    txt = re.sub(\"not\\s\", \"not\", txt)\n",
        "    txt = re.sub(\"no\\s\", \"no\", txt)\n",
        "    \n",
        "    txt = [lemmatizer.lemmatize(word) for word in txt.split()] # лемматизация\n",
        "    txt = [word for word in txt if word not in sw]\n",
        "    return ' '.join(txt)"
      ],
      "metadata": {
        "id": "tWC77eK3zmlR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "tqdm.pandas()\n",
        "\n",
        "X_train['tweet'] = X_train['tweet'].progress_apply(preprocess_text)\n",
        "X_val['tweet'] = X_val['tweet'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0uGUePy0I5B",
        "outputId": "eef58b15-73fe-4c70-bdab-3fb924d74985"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25569/25569 [00:03<00:00, 8054.25it/s] \n",
            "100%|██████████| 6393/6393 [00:00<00:00, 14653.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим общий корпус текста:"
      ],
      "metadata": {
        "id": "M9eUxmsY8E2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(X_train[\"tweet\"])\n",
        "train_corpus = train_corpus.lower()\n",
        "# train_corpus"
      ],
      "metadata": {
        "id": "oqBxHsEN8Ff5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем токенизацию:"
      ],
      "metadata": {
        "id": "DeqkAzwT8X47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql9O7vaS8Ysw",
        "outputId": "a8e041d7-ddcb-4ce4-fabb-7739a9d12eed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first',\n",
              " 'order',\n",
              " 'something',\n",
              " 'black',\n",
              " 'amp',\n",
              " 'sexy',\n",
              " 's',\n",
              " 'collection',\n",
              " 'cantwait',\n",
              " 'although']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "7IjUWtjE8dgH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]  # вычитание 1 для padding\n",
        "len(tokens_filtered_top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p65GRPdi8wnf",
        "outputId": "ce3ca7f6-5eb2-4959-e6a6-f440f1c2ffcf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1499"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Посмотрим на топ 10 слов\n",
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58AKLrtF82eo",
        "outputId": "816f8d05-f6f8-4da5-c386-b7b7c1faa73f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love', 'day', 'happy', 'u', 'amp', 'just', 'will', 'life', 'time', 'im']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "# vocabulary"
      ],
      "metadata": {
        "id": "nwPTC0vSAmhF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ],
      "metadata": {
        "id": "jw948BRFD-vp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train['tweet']])\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in X_val['tweet']])\n",
        "\n",
        "x_train.shape, x_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EpES-X4EEMj",
        "outputId": "386be508-a563-426c-9933-1c359fab1134"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.84 s, sys: 10.7 ms, total: 2.85 s\n",
            "Wall time: 2.86 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25569, 15), (6393, 15))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['tweet'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D_fnlPCPENNc",
        "outputId": "0c048b6e-bf5d-43bd-ab5c-0637bce80a94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first order something black amp sexy s collection cantwait'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSnDzhh_EP0C",
        "outputId": "7f378ea3-0208-4a02-f38d-40cb8dee0ed2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  55,  482,  231,  127,    5,  298,  301, 1130,  586,    0,    0,\n",
              "          0,    0,    0,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "nXSjwtdL9_IC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собираем сеть."
      ],
      "metadata": {
        "id": "2l7OEFWeEWR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "nUCVcAxzFWO3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "RU4oBb9-EeG6"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataWrapper(x_train, X_train['label'].values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(x_val, X_val['label'].values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "4AIUy1KsE0Eq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_LTSM = LSTMFixedLen(vocab_size=max_words, embedding_dim=embedding_dim)\n",
        "\n",
        "print(model_LTSM)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model_LTSM.parameters()]))\n",
        "\n",
        "# компиляция модели\n",
        "optimizer = torch.optim.Adam(model_LTSM.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zPWaLKnSDhV",
        "outputId": "9fff9e54-f85b-448c-f1f6-fce0efafafe2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(1500, 256, padding_idx=0)\n",
            "  (lstm): LSTM(256, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Parameters: 713857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим функцию для проверки"
      ],
      "metadata": {
        "id": "WoQrhG5NS8qB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn(th=0.5, vocab_size=1500, embedding_dim=128, learning_rate=1e-3, epochs=epochs, batch_size=batch_size, visual=False):\n",
        "\n",
        "  random_state = 42\n",
        "\n",
        "  # max_words = 1500\n",
        "  max_len = 15\n",
        "  num_classes = 1\n",
        "\n",
        "  # Training\n",
        "  epochs = epochs\n",
        "  batch_size = batch_size\n",
        "  # embedding_dim = 256\n",
        "  # out_channel = 256\n",
        "\n",
        "  model_LTSM = LSTMFixedLen(vocab_size, embedding_dim)\n",
        "  optimizer = torch.optim.Adam(model_LTSM.parameters(), lr=learning_rate)\n",
        "  criterion = nn.BCELoss()\n",
        "\n",
        "  print(\"Parameters of model:\", sum([param.nelement() for param in model_LTSM.parameters()]))\n",
        "\n",
        "  model_LTSM = model_LTSM.to(device)\n",
        "  model_LTSM.train()\n",
        "  th = th\n",
        "\n",
        "  train_loss_history = []\n",
        "  test_loss_history = []\n",
        "  train_f1_history = []\n",
        "  test_f1_history = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "  \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_LTSM(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "\n",
        "        tp += ((labels == 1) & (pred_labels == 1)).sum().item()\n",
        "        tn += ((labels == 0) & (pred_labels == 0)).sum().item()\n",
        "        fp += ((labels == 0) & (pred_labels == 1)).sum().item()\n",
        "        fn += ((labels == 1) & (pred_labels == 0)).sum().item()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    model_LTSM.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "          # f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "          f'Loss: {loss:.3f}. ' \\\n",
        "          f'Acc: {running_right / running_items:.3f}',\n",
        "          f'F1-score: {f1_score:.3f}', end='. ')\n",
        "    \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "    train_loss_history.append(loss)\n",
        "    train_f1_history.append(f1_score)\n",
        "    # print(train_f1_history)\n",
        "\n",
        "    # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    test_tp, test_fp, test_tn, test_fn = 0, 0, 0, 0\n",
        "\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = model_LTSM(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "        test_tp += ((test_labels == 1) & (pred_test_labels == 1)).sum().item()\n",
        "        test_tn += ((test_labels == 0) & (pred_test_labels == 0)).sum().item()\n",
        "        test_fp += ((test_labels == 0) & (pred_test_labels == 1)).sum().item()\n",
        "        test_fn += ((test_labels == 1) & (pred_test_labels == 0)).sum().item()\n",
        "\n",
        "    test_precision = test_tp / (test_tp + test_fp) if (test_tp + test_fp) != 0 else 0\n",
        "    test_recall = test_tp / (test_tp + test_fn) if (test_tp + test_fn) != 0 else 0\n",
        "\n",
        "    test_f1_score = 2 * test_precision * test_recall / (test_precision + test_recall) if (test_precision + test_recall) != 0 else 0\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    test_f1_history.append(test_f1_score)\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}. Test F1_score: {test_f1_score:.3f}. Recall: {test_recall:.3f}')\n",
        "    \n",
        "    model_LTSM.train()\n",
        "\n",
        "  if visual is True:\n",
        "   \n",
        "    plt.title('F1 history')\n",
        "    plt.grid(True)\n",
        "    plt.ylabel('F1 score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(train_f1_history, label='train')\n",
        "    plt.plot(test_f1_history, label='test')\n",
        "    plt.legend();\n",
        "        \n",
        "  print('Training is finished!')\n",
        "\n",
        "  return test_f1_history[-1]"
      ],
      "metadata": {
        "id": "3vuAobbCSQwz"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_nn(visual=True)"
      ],
      "metadata": {
        "id": "uJ4KiVuYV75U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = [10, 15]\n",
        "learning_rates = [1e-2, 1e-3]\n",
        "e_dims = [128, 256]\n",
        "h_dims = [64, 96]\n",
        "ths = [0.3, 0.5]"
      ],
      "metadata": {
        "id": "23WMBBf5Vuwk"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из-за несбалансированности классов использование accuracy несколько непрезентативно. Будем использовать F1-score."
      ],
      "metadata": {
        "id": "vt5vryBdo5Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_tab = []\n",
        "epch_tab = []\n",
        "lr_tab = []\n",
        "thr_tab = []\n",
        "emb_dim_tab = []\n",
        "\n",
        "for epch in n_epochs:\n",
        "  for lr in learning_rates:\n",
        "    for thr in ths:\n",
        "      for e in e_dims:\n",
        "        print('\\033[1m' + f'Количество эпох: {epch} \\nШаг обучения: {lr}' + '\\033[0m')\n",
        "        epch_tab.append(epch)\n",
        "        lr_tab.append(lr)\n",
        "        thr_tab.append(thr)\n",
        "        emb_dim_tab.append(e)\n",
        "        f1_tab.append(round(train_nn(learning_rate=lr, epochs=epch, th=thr, embedding_dim=e), 3))\n",
        "        print('-' * 50)\n",
        "        print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fikl4M0WVz17",
        "outputId": "c57ab407-780b-46f9-ee39-9272d0a57f80"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/10]. Loss: 0.179. Acc: 0.895 F1-score: 0.285. Test loss: 0.218. Test acc: 0.926. Test F1_score: 0.508. Recall: 0.547\n",
            "Epoch [2/10]. Loss: 0.190. Acc: 0.939 F1-score: 0.540. Test loss: 0.249. Test acc: 0.947. Test F1_score: 0.497. Recall: 0.375\n",
            "Epoch [3/10]. Loss: 0.164. Acc: 0.944 F1-score: 0.588. Test loss: 0.095. Test acc: 0.947. Test F1_score: 0.596. Recall: 0.554\n",
            "Epoch [4/10]. Loss: 0.137. Acc: 0.954 F1-score: 0.660. Test loss: 0.139. Test acc: 0.950. Test F1_score: 0.588. Recall: 0.509\n",
            "Epoch [5/10]. Loss: 0.091. Acc: 0.955 F1-score: 0.672. Test loss: 0.114. Test acc: 0.945. Test F1_score: 0.596. Recall: 0.580\n",
            "Epoch [6/10]. Loss: 0.083. Acc: 0.955 F1-score: 0.689. Test loss: 0.170. Test acc: 0.947. Test F1_score: 0.589. Recall: 0.540\n",
            "Epoch [7/10]. Loss: 0.064. Acc: 0.960 F1-score: 0.710. Test loss: 0.203. Test acc: 0.938. Test F1_score: 0.586. Recall: 0.627\n",
            "Epoch [8/10]. Loss: 0.115. Acc: 0.964 F1-score: 0.746. Test loss: 0.180. Test acc: 0.944. Test F1_score: 0.594. Recall: 0.589\n",
            "Epoch [9/10]. Loss: 0.079. Acc: 0.968 F1-score: 0.768. Test loss: 0.184. Test acc: 0.947. Test F1_score: 0.603. Recall: 0.571\n",
            "Epoch [10/10]. Loss: 0.083. Acc: 0.969 F1-score: 0.780. Test loss: 0.205. Test acc: 0.943. Test F1_score: 0.571. Recall: 0.542\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/10]. Loss: 0.220. Acc: 0.893 F1-score: 0.283. Test loss: 0.218. Test acc: 0.911. Test F1_score: 0.420. Recall: 0.460\n",
            "Epoch [2/10]. Loss: 0.144. Acc: 0.925 F1-score: 0.468. Test loss: 0.206. Test acc: 0.940. Test F1_score: 0.459. Recall: 0.366\n",
            "Epoch [3/10]. Loss: 0.135. Acc: 0.937 F1-score: 0.552. Test loss: 0.116. Test acc: 0.944. Test F1_score: 0.562. Recall: 0.516\n",
            "Epoch [4/10]. Loss: 0.092. Acc: 0.948 F1-score: 0.632. Test loss: 0.196. Test acc: 0.944. Test F1_score: 0.601. Recall: 0.598\n",
            "Epoch [5/10]. Loss: 0.107. Acc: 0.957 F1-score: 0.709. Test loss: 0.135. Test acc: 0.942. Test F1_score: 0.605. Recall: 0.629\n",
            "Epoch [6/10]. Loss: 0.053. Acc: 0.963 F1-score: 0.742. Test loss: 0.277. Test acc: 0.950. Test F1_score: 0.618. Recall: 0.576\n",
            "Epoch [7/10]. Loss: 0.073. Acc: 0.968 F1-score: 0.780. Test loss: 0.132. Test acc: 0.946. Test F1_score: 0.604. Recall: 0.585\n",
            "Epoch [8/10]. Loss: 0.087. Acc: 0.972 F1-score: 0.807. Test loss: 0.248. Test acc: 0.943. Test F1_score: 0.603. Recall: 0.614\n",
            "Epoch [9/10]. Loss: 0.054. Acc: 0.975 F1-score: 0.824. Test loss: 0.168. Test acc: 0.951. Test F1_score: 0.624. Recall: 0.578\n",
            "Epoch [10/10]. Loss: 0.053. Acc: 0.977 F1-score: 0.838. Test loss: 0.322. Test acc: 0.944. Test F1_score: 0.602. Recall: 0.605\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/10]. Loss: 0.235. Acc: 0.915 F1-score: 0.242. Test loss: 0.208. Test acc: 0.927. Test F1_score: 0.190. Recall: 0.123\n",
            "Epoch [2/10]. Loss: 0.214. Acc: 0.934 F1-score: 0.248. Test loss: 0.191. Test acc: 0.934. Test F1_score: 0.117. Recall: 0.062\n",
            "Epoch [3/10]. Loss: 0.172. Acc: 0.945 F1-score: 0.464. Test loss: 0.249. Test acc: 0.944. Test F1_score: 0.369. Recall: 0.234\n",
            "Epoch [4/10]. Loss: 0.117. Acc: 0.949 F1-score: 0.524. Test loss: 0.133. Test acc: 0.947. Test F1_score: 0.519. Recall: 0.404\n",
            "Epoch [5/10]. Loss: 0.119. Acc: 0.954 F1-score: 0.569. Test loss: 0.123. Test acc: 0.949. Test F1_score: 0.530. Recall: 0.408\n",
            "Epoch [6/10]. Loss: 0.136. Acc: 0.957 F1-score: 0.613. Test loss: 0.131. Test acc: 0.949. Test F1_score: 0.547. Recall: 0.438\n",
            "Epoch [7/10]. Loss: 0.113. Acc: 0.958 F1-score: 0.648. Test loss: 0.225. Test acc: 0.952. Test F1_score: 0.606. Recall: 0.531\n",
            "Epoch [8/10]. Loss: 0.114. Acc: 0.961 F1-score: 0.692. Test loss: 0.225. Test acc: 0.951. Test F1_score: 0.583. Recall: 0.493\n",
            "Epoch [9/10]. Loss: 0.087. Acc: 0.967 F1-score: 0.747. Test loss: 0.129. Test acc: 0.950. Test F1_score: 0.581. Recall: 0.493\n",
            "Epoch [10/10]. Loss: 0.072. Acc: 0.970 F1-score: 0.766. Test loss: 0.190. Test acc: 0.947. Test F1_score: 0.595. Recall: 0.558\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/10]. Loss: 0.238. Acc: 0.912 F1-score: 0.054. Test loss: 0.208. Test acc: 0.930. Test F1_score: 0.000. Recall: 0.000\n",
            "Epoch [2/10]. Loss: 0.169. Acc: 0.930 F1-score: 0.000. Test loss: 0.195. Test acc: 0.930. Test F1_score: 0.000. Recall: 0.000\n",
            "Epoch [3/10]. Loss: 0.195. Acc: 0.929 F1-score: 0.079. Test loss: 0.169. Test acc: 0.930. Test F1_score: 0.000. Recall: 0.000\n",
            "Epoch [4/10]. Loss: 0.127. Acc: 0.939 F1-score: 0.451. Test loss: 0.172. Test acc: 0.944. Test F1_score: 0.546. Recall: 0.482\n",
            "Epoch [5/10]. Loss: 0.159. Acc: 0.952 F1-score: 0.645. Test loss: 0.117. Test acc: 0.945. Test F1_score: 0.539. Recall: 0.458\n",
            "Epoch [6/10]. Loss: 0.114. Acc: 0.961 F1-score: 0.708. Test loss: 0.144. Test acc: 0.947. Test F1_score: 0.570. Recall: 0.507\n",
            "Epoch [7/10]. Loss: 0.095. Acc: 0.961 F1-score: 0.713. Test loss: 0.181. Test acc: 0.942. Test F1_score: 0.559. Recall: 0.527\n",
            "Epoch [8/10]. Loss: 0.082. Acc: 0.966 F1-score: 0.746. Test loss: 0.117. Test acc: 0.949. Test F1_score: 0.561. Recall: 0.469\n",
            "Epoch [9/10]. Loss: 0.097. Acc: 0.968 F1-score: 0.761. Test loss: 0.233. Test acc: 0.944. Test F1_score: 0.576. Recall: 0.538\n",
            "Epoch [10/10]. Loss: 0.049. Acc: 0.975 F1-score: 0.819. Test loss: 0.313. Test acc: 0.949. Test F1_score: 0.576. Recall: 0.496\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/10]. Loss: 0.224. Acc: 0.760 F1-score: 0.121. Test loss: 0.216. Test acc: 0.934. Test F1_score: 0.292. Recall: 0.194\n",
            "Epoch [2/10]. Loss: 0.193. Acc: 0.934 F1-score: 0.431. Test loss: 0.151. Test acc: 0.945. Test F1_score: 0.528. Recall: 0.440\n",
            "Epoch [3/10]. Loss: 0.138. Acc: 0.948 F1-score: 0.580. Test loss: 0.127. Test acc: 0.945. Test F1_score: 0.595. Recall: 0.578\n",
            "Epoch [4/10]. Loss: 0.136. Acc: 0.951 F1-score: 0.630. Test loss: 0.128. Test acc: 0.950. Test F1_score: 0.621. Recall: 0.583\n",
            "Epoch [5/10]. Loss: 0.132. Acc: 0.954 F1-score: 0.671. Test loss: 0.153. Test acc: 0.946. Test F1_score: 0.603. Recall: 0.589\n",
            "Epoch [6/10]. Loss: 0.098. Acc: 0.957 F1-score: 0.699. Test loss: 0.171. Test acc: 0.944. Test F1_score: 0.614. Recall: 0.638\n",
            "Epoch [7/10]. Loss: 0.106. Acc: 0.962 F1-score: 0.732. Test loss: 0.181. Test acc: 0.940. Test F1_score: 0.593. Recall: 0.621\n",
            "Epoch [8/10]. Loss: 0.113. Acc: 0.966 F1-score: 0.760. Test loss: 0.169. Test acc: 0.946. Test F1_score: 0.618. Recall: 0.621\n",
            "Epoch [9/10]. Loss: 0.041. Acc: 0.971 F1-score: 0.797. Test loss: 0.244. Test acc: 0.943. Test F1_score: 0.610. Recall: 0.636\n",
            "Epoch [10/10]. Loss: 0.074. Acc: 0.972 F1-score: 0.807. Test loss: 0.245. Test acc: 0.949. Test F1_score: 0.610. Recall: 0.574\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/10]. Loss: 0.162. Acc: 0.763 F1-score: 0.149. Test loss: 0.176. Test acc: 0.931. Test F1_score: 0.480. Recall: 0.453\n",
            "Epoch [2/10]. Loss: 0.154. Acc: 0.942 F1-score: 0.552. Test loss: 0.202. Test acc: 0.950. Test F1_score: 0.593. Recall: 0.525\n",
            "Epoch [3/10]. Loss: 0.155. Acc: 0.952 F1-score: 0.636. Test loss: 0.160. Test acc: 0.952. Test F1_score: 0.621. Recall: 0.562\n",
            "Epoch [4/10]. Loss: 0.102. Acc: 0.957 F1-score: 0.686. Test loss: 0.174. Test acc: 0.948. Test F1_score: 0.626. Recall: 0.621\n",
            "Epoch [5/10]. Loss: 0.103. Acc: 0.960 F1-score: 0.718. Test loss: 0.119. Test acc: 0.948. Test F1_score: 0.626. Recall: 0.625\n",
            "Epoch [6/10]. Loss: 0.102. Acc: 0.966 F1-score: 0.765. Test loss: 0.202. Test acc: 0.945. Test F1_score: 0.606. Recall: 0.600\n",
            "Epoch [7/10]. Loss: 0.037. Acc: 0.970 F1-score: 0.795. Test loss: 0.203. Test acc: 0.947. Test F1_score: 0.615. Recall: 0.600\n",
            "Epoch [8/10]. Loss: 0.060. Acc: 0.976 F1-score: 0.835. Test loss: 0.197. Test acc: 0.940. Test F1_score: 0.597. Recall: 0.629\n",
            "Epoch [9/10]. Loss: 0.043. Acc: 0.981 F1-score: 0.867. Test loss: 0.115. Test acc: 0.944. Test F1_score: 0.605. Recall: 0.618\n",
            "Epoch [10/10]. Loss: 0.034. Acc: 0.984 F1-score: 0.889. Test loss: 0.260. Test acc: 0.940. Test F1_score: 0.587. Recall: 0.605\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/10]. Loss: 0.218. Acc: 0.899 F1-score: 0.072. Test loss: 0.249. Test acc: 0.935. Test F1_score: 0.273. Recall: 0.174\n",
            "Epoch [2/10]. Loss: 0.175. Acc: 0.938 F1-score: 0.403. Test loss: 0.148. Test acc: 0.941. Test F1_score: 0.487. Recall: 0.400\n",
            "Epoch [3/10]. Loss: 0.123. Acc: 0.950 F1-score: 0.551. Test loss: 0.223. Test acc: 0.948. Test F1_score: 0.507. Recall: 0.384\n",
            "Epoch [4/10]. Loss: 0.119. Acc: 0.956 F1-score: 0.611. Test loss: 0.112. Test acc: 0.950. Test F1_score: 0.571. Recall: 0.473\n",
            "Epoch [5/10]. Loss: 0.114. Acc: 0.959 F1-score: 0.650. Test loss: 0.187. Test acc: 0.951. Test F1_score: 0.596. Recall: 0.516\n",
            "Epoch [6/10]. Loss: 0.084. Acc: 0.962 F1-score: 0.678. Test loss: 0.146. Test acc: 0.951. Test F1_score: 0.611. Recall: 0.545\n",
            "Epoch [7/10]. Loss: 0.091. Acc: 0.966 F1-score: 0.726. Test loss: 0.047. Test acc: 0.952. Test F1_score: 0.577. Recall: 0.469\n",
            "Epoch [8/10]. Loss: 0.069. Acc: 0.968 F1-score: 0.741. Test loss: 0.074. Test acc: 0.950. Test F1_score: 0.598. Recall: 0.531\n",
            "Epoch [9/10]. Loss: 0.067. Acc: 0.971 F1-score: 0.773. Test loss: 0.160. Test acc: 0.948. Test F1_score: 0.605. Recall: 0.569\n",
            "Epoch [10/10]. Loss: 0.082. Acc: 0.976 F1-score: 0.818. Test loss: 0.235. Test acc: 0.944. Test F1_score: 0.586. Recall: 0.571\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/10]. Loss: 0.156. Acc: 0.931 F1-score: 0.101. Test loss: 0.203. Test acc: 0.935. Test F1_score: 0.438. Recall: 0.362\n",
            "Epoch [2/10]. Loss: 0.136. Acc: 0.947 F1-score: 0.517. Test loss: 0.105. Test acc: 0.949. Test F1_score: 0.532. Recall: 0.411\n",
            "Epoch [3/10]. Loss: 0.134. Acc: 0.956 F1-score: 0.616. Test loss: 0.127. Test acc: 0.950. Test F1_score: 0.569. Recall: 0.469\n",
            "Epoch [4/10]. Loss: 0.118. Acc: 0.960 F1-score: 0.667. Test loss: 0.180. Test acc: 0.953. Test F1_score: 0.598. Recall: 0.502\n",
            "Epoch [5/10]. Loss: 0.142. Acc: 0.965 F1-score: 0.715. Test loss: 0.183. Test acc: 0.952. Test F1_score: 0.599. Recall: 0.516\n",
            "Epoch [6/10]. Loss: 0.081. Acc: 0.969 F1-score: 0.756. Test loss: 0.121. Test acc: 0.951. Test F1_score: 0.624. Recall: 0.578\n",
            "Epoch [7/10]. Loss: 0.094. Acc: 0.973 F1-score: 0.787. Test loss: 0.137. Test acc: 0.953. Test F1_score: 0.624. Recall: 0.551\n",
            "Epoch [8/10]. Loss: 0.068. Acc: 0.977 F1-score: 0.828. Test loss: 0.219. Test acc: 0.945. Test F1_score: 0.582. Recall: 0.545\n",
            "Epoch [9/10]. Loss: 0.086. Acc: 0.981 F1-score: 0.859. Test loss: 0.196. Test acc: 0.947. Test F1_score: 0.616. Recall: 0.603\n",
            "Epoch [10/10]. Loss: 0.074. Acc: 0.984 F1-score: 0.881. Test loss: 0.146. Test acc: 0.943. Test F1_score: 0.590. Recall: 0.580\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/15]. Loss: 0.228. Acc: 0.893 F1-score: 0.100. Test loss: 0.192. Test acc: 0.930. Test F1_score: 0.000. Recall: 0.000\n",
            "Epoch [2/15]. Loss: 0.162. Acc: 0.934 F1-score: 0.282. Test loss: 0.158. Test acc: 0.942. Test F1_score: 0.528. Recall: 0.460\n",
            "Epoch [3/15]. Loss: 0.167. Acc: 0.941 F1-score: 0.544. Test loss: 0.197. Test acc: 0.949. Test F1_score: 0.553. Recall: 0.451\n",
            "Epoch [4/15]. Loss: 0.103. Acc: 0.950 F1-score: 0.615. Test loss: 0.203. Test acc: 0.947. Test F1_score: 0.575. Recall: 0.516\n",
            "Epoch [5/15]. Loss: 0.129. Acc: 0.953 F1-score: 0.651. Test loss: 0.165. Test acc: 0.948. Test F1_score: 0.602. Recall: 0.560\n",
            "Epoch [6/15]. Loss: 0.108. Acc: 0.959 F1-score: 0.693. Test loss: 0.171. Test acc: 0.947. Test F1_score: 0.593. Recall: 0.549\n",
            "Epoch [7/15]. Loss: 0.112. Acc: 0.965 F1-score: 0.739. Test loss: 0.087. Test acc: 0.940. Test F1_score: 0.590. Recall: 0.621\n",
            "Epoch [8/15]. Loss: 0.083. Acc: 0.965 F1-score: 0.749. Test loss: 0.082. Test acc: 0.946. Test F1_score: 0.591. Recall: 0.556\n",
            "Epoch [9/15]. Loss: 0.071. Acc: 0.970 F1-score: 0.787. Test loss: 0.215. Test acc: 0.944. Test F1_score: 0.595. Recall: 0.589\n",
            "Epoch [10/15]. Loss: 0.093. Acc: 0.973 F1-score: 0.808. Test loss: 0.193. Test acc: 0.943. Test F1_score: 0.584. Recall: 0.576\n",
            "Epoch [11/15]. Loss: 0.068. Acc: 0.976 F1-score: 0.832. Test loss: 0.147. Test acc: 0.942. Test F1_score: 0.597. Recall: 0.612\n",
            "Epoch [12/15]. Loss: 0.065. Acc: 0.979 F1-score: 0.853. Test loss: 0.276. Test acc: 0.943. Test F1_score: 0.589. Recall: 0.585\n",
            "Epoch [13/15]. Loss: 0.044. Acc: 0.982 F1-score: 0.874. Test loss: 0.189. Test acc: 0.943. Test F1_score: 0.591. Recall: 0.585\n",
            "Epoch [14/15]. Loss: 0.030. Acc: 0.984 F1-score: 0.889. Test loss: 0.174. Test acc: 0.940. Test F1_score: 0.579. Recall: 0.587\n",
            "Epoch [15/15]. Loss: 0.037. Acc: 0.985 F1-score: 0.893. Test loss: 0.098. Test acc: 0.944. Test F1_score: 0.590. Recall: 0.576\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/15]. Loss: 0.240. Acc: 0.890 F1-score: 0.193. Test loss: 0.227. Test acc: 0.927. Test F1_score: 0.428. Recall: 0.391\n",
            "Epoch [2/15]. Loss: 0.173. Acc: 0.936 F1-score: 0.487. Test loss: 0.228. Test acc: 0.932. Test F1_score: 0.506. Recall: 0.498\n",
            "Epoch [3/15]. Loss: 0.157. Acc: 0.949 F1-score: 0.605. Test loss: 0.183. Test acc: 0.945. Test F1_score: 0.557. Recall: 0.489\n",
            "Epoch [4/15]. Loss: 0.129. Acc: 0.956 F1-score: 0.669. Test loss: 0.163. Test acc: 0.940. Test F1_score: 0.575. Recall: 0.583\n",
            "Epoch [5/15]. Loss: 0.102. Acc: 0.957 F1-score: 0.695. Test loss: 0.173. Test acc: 0.941. Test F1_score: 0.584. Recall: 0.585\n",
            "Epoch [6/15]. Loss: 0.097. Acc: 0.964 F1-score: 0.743. Test loss: 0.147. Test acc: 0.942. Test F1_score: 0.584. Recall: 0.585\n",
            "Epoch [7/15]. Loss: 0.103. Acc: 0.966 F1-score: 0.762. Test loss: 0.234. Test acc: 0.947. Test F1_score: 0.592. Recall: 0.551\n",
            "Epoch [8/15]. Loss: 0.073. Acc: 0.967 F1-score: 0.771. Test loss: 0.207. Test acc: 0.946. Test F1_score: 0.591. Recall: 0.560\n",
            "Epoch [9/15]. Loss: 0.052. Acc: 0.970 F1-score: 0.795. Test loss: 0.186. Test acc: 0.943. Test F1_score: 0.595. Recall: 0.594\n",
            "Epoch [10/15]. Loss: 0.052. Acc: 0.975 F1-score: 0.828. Test loss: 0.106. Test acc: 0.944. Test F1_score: 0.598. Recall: 0.598\n",
            "Epoch [11/15]. Loss: 0.062. Acc: 0.978 F1-score: 0.851. Test loss: 0.203. Test acc: 0.945. Test F1_score: 0.604. Recall: 0.598\n",
            "Epoch [12/15]. Loss: 0.048. Acc: 0.983 F1-score: 0.880. Test loss: 0.244. Test acc: 0.936. Test F1_score: 0.576. Recall: 0.621\n",
            "Epoch [13/15]. Loss: 0.049. Acc: 0.981 F1-score: 0.865. Test loss: 0.240. Test acc: 0.942. Test F1_score: 0.591. Recall: 0.598\n",
            "Epoch [14/15]. Loss: 0.037. Acc: 0.986 F1-score: 0.898. Test loss: 0.221. Test acc: 0.943. Test F1_score: 0.596. Recall: 0.596\n",
            "Epoch [15/15]. Loss: 0.029. Acc: 0.987 F1-score: 0.910. Test loss: 0.333. Test acc: 0.945. Test F1_score: 0.578. Recall: 0.538\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/15]. Loss: 0.251. Acc: 0.931 F1-score: 0.176. Test loss: 0.218. Test acc: 0.930. Test F1_score: 0.009. Recall: 0.004\n",
            "Epoch [2/15]. Loss: 0.180. Acc: 0.938 F1-score: 0.431. Test loss: 0.193. Test acc: 0.939. Test F1_score: 0.481. Recall: 0.402\n",
            "Epoch [3/15]. Loss: 0.138. Acc: 0.950 F1-score: 0.556. Test loss: 0.126. Test acc: 0.947. Test F1_score: 0.554. Recall: 0.467\n",
            "Epoch [4/15]. Loss: 0.123. Acc: 0.956 F1-score: 0.626. Test loss: 0.222. Test acc: 0.951. Test F1_score: 0.600. Recall: 0.525\n",
            "Epoch [5/15]. Loss: 0.128. Acc: 0.960 F1-score: 0.670. Test loss: 0.127. Test acc: 0.948. Test F1_score: 0.573. Recall: 0.496\n",
            "Epoch [6/15]. Loss: 0.109. Acc: 0.964 F1-score: 0.703. Test loss: 0.219. Test acc: 0.953. Test F1_score: 0.594. Recall: 0.496\n",
            "Epoch [7/15]. Loss: 0.087. Acc: 0.968 F1-score: 0.730. Test loss: 0.146. Test acc: 0.949. Test F1_score: 0.580. Recall: 0.500\n",
            "Epoch [8/15]. Loss: 0.076. Acc: 0.970 F1-score: 0.754. Test loss: 0.161. Test acc: 0.950. Test F1_score: 0.600. Recall: 0.533\n",
            "Epoch [9/15]. Loss: 0.065. Acc: 0.974 F1-score: 0.793. Test loss: 0.116. Test acc: 0.953. Test F1_score: 0.571. Recall: 0.444\n",
            "Epoch [10/15]. Loss: 0.066. Acc: 0.978 F1-score: 0.826. Test loss: 0.124. Test acc: 0.950. Test F1_score: 0.576. Recall: 0.482\n",
            "Epoch [11/15]. Loss: 0.052. Acc: 0.980 F1-score: 0.850. Test loss: 0.223. Test acc: 0.949. Test F1_score: 0.605. Recall: 0.562\n",
            "Epoch [12/15]. Loss: 0.077. Acc: 0.983 F1-score: 0.874. Test loss: 0.222. Test acc: 0.947. Test F1_score: 0.595. Recall: 0.554\n",
            "Epoch [13/15]. Loss: 0.064. Acc: 0.985 F1-score: 0.888. Test loss: 0.123. Test acc: 0.945. Test F1_score: 0.574. Recall: 0.525\n",
            "Epoch [14/15]. Loss: 0.037. Acc: 0.985 F1-score: 0.888. Test loss: 0.259. Test acc: 0.944. Test F1_score: 0.573. Recall: 0.531\n",
            "Epoch [15/15]. Loss: 0.048. Acc: 0.987 F1-score: 0.906. Test loss: 0.187. Test acc: 0.947. Test F1_score: 0.591. Recall: 0.542\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/15]. Loss: 0.231. Acc: 0.931 F1-score: 0.147. Test loss: 0.170. Test acc: 0.930. Test F1_score: 0.000. Recall: 0.000\n",
            "Epoch [2/15]. Loss: 0.214. Acc: 0.935 F1-score: 0.269. Test loss: 0.197. Test acc: 0.942. Test F1_score: 0.497. Recall: 0.411\n",
            "Epoch [3/15]. Loss: 0.156. Acc: 0.950 F1-score: 0.549. Test loss: 0.136. Test acc: 0.947. Test F1_score: 0.458. Recall: 0.321\n",
            "Epoch [4/15]. Loss: 0.094. Acc: 0.953 F1-score: 0.574. Test loss: 0.135. Test acc: 0.948. Test F1_score: 0.573. Recall: 0.498\n",
            "Epoch [5/15]. Loss: 0.131. Acc: 0.958 F1-score: 0.654. Test loss: 0.160. Test acc: 0.949. Test F1_score: 0.587. Recall: 0.513\n",
            "Epoch [6/15]. Loss: 0.097. Acc: 0.966 F1-score: 0.726. Test loss: 0.115. Test acc: 0.948. Test F1_score: 0.593. Recall: 0.542\n",
            "Epoch [7/15]. Loss: 0.094. Acc: 0.970 F1-score: 0.764. Test loss: 0.140. Test acc: 0.949. Test F1_score: 0.588. Recall: 0.522\n",
            "Epoch [8/15]. Loss: 0.095. Acc: 0.974 F1-score: 0.804. Test loss: 0.182. Test acc: 0.946. Test F1_score: 0.581. Recall: 0.538\n",
            "Epoch [9/15]. Loss: 0.085. Acc: 0.977 F1-score: 0.829. Test loss: 0.196. Test acc: 0.949. Test F1_score: 0.597. Recall: 0.536\n",
            "Epoch [10/15]. Loss: 0.080. Acc: 0.980 F1-score: 0.847. Test loss: 0.210. Test acc: 0.943. Test F1_score: 0.602. Recall: 0.614\n",
            "Epoch [11/15]. Loss: 0.057. Acc: 0.982 F1-score: 0.868. Test loss: 0.136. Test acc: 0.950. Test F1_score: 0.605. Recall: 0.549\n",
            "Epoch [12/15]. Loss: 0.037. Acc: 0.985 F1-score: 0.889. Test loss: 0.238. Test acc: 0.946. Test F1_score: 0.597. Recall: 0.567\n",
            "Epoch [13/15]. Loss: 0.023. Acc: 0.987 F1-score: 0.904. Test loss: 0.182. Test acc: 0.951. Test F1_score: 0.621. Recall: 0.569\n",
            "Epoch [14/15]. Loss: 0.027. Acc: 0.987 F1-score: 0.906. Test loss: 0.149. Test acc: 0.952. Test F1_score: 0.626. Recall: 0.576\n",
            "Epoch [15/15]. Loss: 0.051. Acc: 0.987 F1-score: 0.903. Test loss: 0.285. Test acc: 0.951. Test F1_score: 0.616. Recall: 0.560\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/15]. Loss: 0.243. Acc: 0.760 F1-score: 0.112. Test loss: 0.282. Test acc: 0.934. Test F1_score: 0.105. Recall: 0.056\n",
            "Epoch [2/15]. Loss: 0.190. Acc: 0.932 F1-score: 0.376. Test loss: 0.150. Test acc: 0.940. Test F1_score: 0.520. Recall: 0.467\n",
            "Epoch [3/15]. Loss: 0.142. Acc: 0.945 F1-score: 0.562. Test loss: 0.152. Test acc: 0.947. Test F1_score: 0.580. Recall: 0.525\n",
            "Epoch [4/15]. Loss: 0.106. Acc: 0.949 F1-score: 0.623. Test loss: 0.157. Test acc: 0.942. Test F1_score: 0.603. Recall: 0.625\n",
            "Epoch [5/15]. Loss: 0.124. Acc: 0.954 F1-score: 0.673. Test loss: 0.107. Test acc: 0.954. Test F1_score: 0.602. Recall: 0.502\n",
            "Epoch [6/15]. Loss: 0.101. Acc: 0.957 F1-score: 0.701. Test loss: 0.126. Test acc: 0.945. Test F1_score: 0.616. Recall: 0.625\n",
            "Epoch [7/15]. Loss: 0.069. Acc: 0.962 F1-score: 0.733. Test loss: 0.150. Test acc: 0.944. Test F1_score: 0.614. Recall: 0.641\n",
            "Epoch [8/15]. Loss: 0.125. Acc: 0.967 F1-score: 0.771. Test loss: 0.226. Test acc: 0.938. Test F1_score: 0.592. Recall: 0.638\n",
            "Epoch [9/15]. Loss: 0.038. Acc: 0.972 F1-score: 0.804. Test loss: 0.178. Test acc: 0.944. Test F1_score: 0.612. Recall: 0.632\n",
            "Epoch [10/15]. Loss: 0.132. Acc: 0.977 F1-score: 0.836. Test loss: 0.156. Test acc: 0.934. Test F1_score: 0.572. Recall: 0.634\n",
            "Epoch [11/15]. Loss: 0.059. Acc: 0.978 F1-score: 0.849. Test loss: 0.151. Test acc: 0.947. Test F1_score: 0.624. Recall: 0.625\n",
            "Epoch [12/15]. Loss: 0.087. Acc: 0.981 F1-score: 0.866. Test loss: 0.108. Test acc: 0.951. Test F1_score: 0.618. Recall: 0.569\n",
            "Epoch [13/15]. Loss: 0.044. Acc: 0.983 F1-score: 0.880. Test loss: 0.223. Test acc: 0.949. Test F1_score: 0.608. Recall: 0.567\n",
            "Epoch [14/15]. Loss: 0.024. Acc: 0.985 F1-score: 0.892. Test loss: 0.193. Test acc: 0.949. Test F1_score: 0.635. Recall: 0.638\n",
            "Epoch [15/15]. Loss: 0.041. Acc: 0.988 F1-score: 0.912. Test loss: 0.218. Test acc: 0.944. Test F1_score: 0.600. Recall: 0.605\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/15]. Loss: 0.200. Acc: 0.761 F1-score: 0.140. Test loss: 0.287. Test acc: 0.931. Test F1_score: 0.464. Recall: 0.424\n",
            "Epoch [2/15]. Loss: 0.122. Acc: 0.940 F1-score: 0.512. Test loss: 0.183. Test acc: 0.938. Test F1_score: 0.529. Recall: 0.500\n",
            "Epoch [3/15]. Loss: 0.098. Acc: 0.952 F1-score: 0.622. Test loss: 0.234. Test acc: 0.948. Test F1_score: 0.599. Recall: 0.554\n",
            "Epoch [4/15]. Loss: 0.117. Acc: 0.954 F1-score: 0.662. Test loss: 0.181. Test acc: 0.946. Test F1_score: 0.613. Recall: 0.616\n",
            "Epoch [5/15]. Loss: 0.098. Acc: 0.959 F1-score: 0.701. Test loss: 0.162. Test acc: 0.947. Test F1_score: 0.602. Recall: 0.571\n",
            "Epoch [6/15]. Loss: 0.116. Acc: 0.962 F1-score: 0.729. Test loss: 0.161. Test acc: 0.951. Test F1_score: 0.625. Recall: 0.585\n",
            "Epoch [7/15]. Loss: 0.103. Acc: 0.966 F1-score: 0.765. Test loss: 0.187. Test acc: 0.946. Test F1_score: 0.601. Recall: 0.583\n",
            "Epoch [8/15]. Loss: 0.068. Acc: 0.972 F1-score: 0.804. Test loss: 0.190. Test acc: 0.940. Test F1_score: 0.589. Recall: 0.614\n",
            "Epoch [9/15]. Loss: 0.058. Acc: 0.976 F1-score: 0.834. Test loss: 0.173. Test acc: 0.948. Test F1_score: 0.604. Recall: 0.569\n",
            "Epoch [10/15]. Loss: 0.064. Acc: 0.982 F1-score: 0.872. Test loss: 0.194. Test acc: 0.942. Test F1_score: 0.596. Recall: 0.609\n",
            "Epoch [11/15]. Loss: 0.034. Acc: 0.984 F1-score: 0.886. Test loss: 0.150. Test acc: 0.949. Test F1_score: 0.613. Recall: 0.574\n",
            "Epoch [12/15]. Loss: 0.034. Acc: 0.985 F1-score: 0.894. Test loss: 0.131. Test acc: 0.946. Test F1_score: 0.605. Recall: 0.587\n",
            "Epoch [13/15]. Loss: 0.028. Acc: 0.989 F1-score: 0.920. Test loss: 0.278. Test acc: 0.949. Test F1_score: 0.615. Recall: 0.578\n",
            "Epoch [14/15]. Loss: 0.030. Acc: 0.990 F1-score: 0.926. Test loss: 0.171. Test acc: 0.947. Test F1_score: 0.616. Recall: 0.603\n",
            "Epoch [15/15]. Loss: 0.014. Acc: 0.991 F1-score: 0.934. Test loss: 0.277. Test acc: 0.949. Test F1_score: 0.618. Recall: 0.587\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 456321\n",
            "Epoch [1/15]. Loss: 0.232. Acc: 0.931 F1-score: 0.039. Test loss: 0.237. Test acc: 0.931. Test F1_score: 0.276. Recall: 0.188\n",
            "Epoch [2/15]. Loss: 0.201. Acc: 0.940 F1-score: 0.395. Test loss: 0.131. Test acc: 0.943. Test F1_score: 0.435. Recall: 0.312\n",
            "Epoch [3/15]. Loss: 0.130. Acc: 0.950 F1-score: 0.529. Test loss: 0.157. Test acc: 0.949. Test F1_score: 0.558. Recall: 0.458\n",
            "Epoch [4/15]. Loss: 0.088. Acc: 0.955 F1-score: 0.607. Test loss: 0.172. Test acc: 0.952. Test F1_score: 0.520. Recall: 0.373\n",
            "Epoch [5/15]. Loss: 0.161. Acc: 0.958 F1-score: 0.645. Test loss: 0.094. Test acc: 0.952. Test F1_score: 0.594. Recall: 0.498\n",
            "Epoch [6/15]. Loss: 0.083. Acc: 0.962 F1-score: 0.687. Test loss: 0.112. Test acc: 0.951. Test F1_score: 0.606. Recall: 0.542\n",
            "Epoch [7/15]. Loss: 0.075. Acc: 0.966 F1-score: 0.729. Test loss: 0.188. Test acc: 0.951. Test F1_score: 0.606. Recall: 0.538\n",
            "Epoch [8/15]. Loss: 0.089. Acc: 0.970 F1-score: 0.770. Test loss: 0.066. Test acc: 0.951. Test F1_score: 0.589. Recall: 0.498\n",
            "Epoch [9/15]. Loss: 0.091. Acc: 0.974 F1-score: 0.799. Test loss: 0.205. Test acc: 0.950. Test F1_score: 0.592. Recall: 0.513\n",
            "Epoch [10/15]. Loss: 0.056. Acc: 0.977 F1-score: 0.822. Test loss: 0.116. Test acc: 0.950. Test F1_score: 0.592. Recall: 0.522\n",
            "Epoch [11/15]. Loss: 0.035. Acc: 0.980 F1-score: 0.848. Test loss: 0.290. Test acc: 0.952. Test F1_score: 0.612. Recall: 0.545\n",
            "Epoch [12/15]. Loss: 0.057. Acc: 0.983 F1-score: 0.873. Test loss: 0.131. Test acc: 0.945. Test F1_score: 0.575. Recall: 0.527\n",
            "Epoch [13/15]. Loss: 0.045. Acc: 0.985 F1-score: 0.890. Test loss: 0.239. Test acc: 0.948. Test F1_score: 0.600. Recall: 0.554\n",
            "Epoch [14/15]. Loss: 0.054. Acc: 0.987 F1-score: 0.908. Test loss: 0.219. Test acc: 0.954. Test F1_score: 0.602. Recall: 0.500\n",
            "Epoch [15/15]. Loss: 0.052. Acc: 0.988 F1-score: 0.910. Test loss: 0.158. Test acc: 0.951. Test F1_score: 0.614. Recall: 0.551\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 713857\n",
            "Epoch [1/15]. Loss: 0.213. Acc: 0.897 F1-score: 0.096. Test loss: 0.138. Test acc: 0.936. Test F1_score: 0.398. Recall: 0.301\n",
            "Epoch [2/15]. Loss: 0.174. Acc: 0.943 F1-score: 0.477. Test loss: 0.152. Test acc: 0.947. Test F1_score: 0.534. Recall: 0.433\n",
            "Epoch [3/15]. Loss: 0.117. Acc: 0.954 F1-score: 0.594. Test loss: 0.110. Test acc: 0.952. Test F1_score: 0.535. Recall: 0.391\n",
            "Epoch [4/15]. Loss: 0.115. Acc: 0.958 F1-score: 0.627. Test loss: 0.147. Test acc: 0.953. Test F1_score: 0.559. Recall: 0.429\n",
            "Epoch [5/15]. Loss: 0.072. Acc: 0.962 F1-score: 0.681. Test loss: 0.110. Test acc: 0.953. Test F1_score: 0.579. Recall: 0.458\n",
            "Epoch [6/15]. Loss: 0.063. Acc: 0.966 F1-score: 0.722. Test loss: 0.110. Test acc: 0.952. Test F1_score: 0.602. Recall: 0.513\n",
            "Epoch [7/15]. Loss: 0.084. Acc: 0.968 F1-score: 0.750. Test loss: 0.155. Test acc: 0.950. Test F1_score: 0.621. Recall: 0.583\n",
            "Epoch [8/15]. Loss: 0.052. Acc: 0.975 F1-score: 0.809. Test loss: 0.102. Test acc: 0.949. Test F1_score: 0.603. Recall: 0.554\n",
            "Epoch [9/15]. Loss: 0.094. Acc: 0.979 F1-score: 0.842. Test loss: 0.247. Test acc: 0.947. Test F1_score: 0.612. Recall: 0.596\n",
            "Epoch [10/15]. Loss: 0.052. Acc: 0.983 F1-score: 0.868. Test loss: 0.233. Test acc: 0.946. Test F1_score: 0.603. Recall: 0.583\n",
            "Epoch [11/15]. Loss: 0.055. Acc: 0.986 F1-score: 0.894. Test loss: 0.150. Test acc: 0.950. Test F1_score: 0.608. Recall: 0.554\n",
            "Epoch [12/15]. Loss: 0.043. Acc: 0.987 F1-score: 0.907. Test loss: 0.150. Test acc: 0.948. Test F1_score: 0.603. Recall: 0.560\n",
            "Epoch [13/15]. Loss: 0.042. Acc: 0.989 F1-score: 0.917. Test loss: 0.199. Test acc: 0.946. Test F1_score: 0.582. Recall: 0.538\n",
            "Epoch [14/15]. Loss: 0.071. Acc: 0.989 F1-score: 0.923. Test loss: 0.262. Test acc: 0.947. Test F1_score: 0.606. Recall: 0.578\n",
            "Epoch [15/15]. Loss: 0.038. Acc: 0.991 F1-score: 0.935. Test loss: 0.183. Test acc: 0.950. Test F1_score: 0.605. Recall: 0.547\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_tab = pd.DataFrame({'epoch': epch_tab,\n",
        "                            'lr': lr_tab, 'th': thr_tab, 'emb_dim': emb_dim_tab,\n",
        "                            'test_f1_score': f1_tab})\n",
        "metrics_tab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "xcZI_cd1wkna",
        "outputId": "fbcfda47-eaae-45f5-b317-1683d633b248"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch     lr   th  emb_dim  test_f1_score\n",
              "0      10  0.010  0.3      128          0.571\n",
              "1      10  0.010  0.3      256          0.602\n",
              "2      10  0.010  0.5      128          0.595\n",
              "3      10  0.010  0.5      256          0.576\n",
              "4      10  0.001  0.3      128          0.610\n",
              "5      10  0.001  0.3      256          0.587\n",
              "6      10  0.001  0.5      128          0.586\n",
              "7      10  0.001  0.5      256          0.590\n",
              "8      15  0.010  0.3      128          0.590\n",
              "9      15  0.010  0.3      256          0.578\n",
              "10     15  0.010  0.5      128          0.591\n",
              "11     15  0.010  0.5      256          0.616\n",
              "12     15  0.001  0.3      128          0.600\n",
              "13     15  0.001  0.3      256          0.618\n",
              "14     15  0.001  0.5      128          0.614\n",
              "15     15  0.001  0.5      256          0.605"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1b56bf3-6395-4c6a-94ec-142676ee34de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>th</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>test_f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1b56bf3-6395-4c6a-94ec-142676ee34de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1b56bf3-6395-4c6a-94ec-142676ee34de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1b56bf3-6395-4c6a-94ec-142676ee34de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_tab.loc[metrics_tab['test_f1_score'] == metrics_tab['test_f1_score'].max()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "rfuCaDjh8DxT",
        "outputId": "ee9ba22f-6074-4d97-d410-ec1cd689b180"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch     lr   th  emb_dim  test_f1_score\n",
              "13     15  0.001  0.3      256          0.618"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d01833fb-9580-4060-8281-4afee8b26b60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>th</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>test_f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d01833fb-9580-4060-8281-4afee8b26b60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d01833fb-9580-4060-8281-4afee8b26b60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d01833fb-9580-4060-8281-4afee8b26b60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лучшая модель по LSTM"
      ],
      "metadata": {
        "id": "ylq4EIRR-Lxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При большом шаге обученния - 0.1 сеть не обучается. Лучшее значение по f1 было получено на 15 эпохах с шагом обучения 0.001, threshold = 0.3"
      ],
      "metadata": {
        "id": "1bNaa_2_61GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_nn(epochs=15, learning_rate=0.001, embedding_dim=256, th=0.3, visual=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "8UJHhM729Y1Z",
        "outputId": "91e5bad1-8b1f-4bc7-8fc4-cbe796e62085"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of model: 713857\n",
            "Epoch [1/15]. Loss: 0.218. Acc: 0.757 F1-score: 0.139. Test loss: 0.142. Test acc: 0.933. Test F1_score: 0.448. Recall: 0.388\n",
            "Epoch [2/15]. Loss: 0.146. Acc: 0.942 F1-score: 0.548. Test loss: 0.124. Test acc: 0.945. Test F1_score: 0.584. Recall: 0.554\n",
            "Epoch [3/15]. Loss: 0.136. Acc: 0.950 F1-score: 0.634. Test loss: 0.162. Test acc: 0.951. Test F1_score: 0.606. Recall: 0.533\n",
            "Epoch [4/15]. Loss: 0.112. Acc: 0.956 F1-score: 0.687. Test loss: 0.114. Test acc: 0.953. Test F1_score: 0.606. Recall: 0.516\n",
            "Epoch [5/15]. Loss: 0.114. Acc: 0.962 F1-score: 0.729. Test loss: 0.145. Test acc: 0.948. Test F1_score: 0.627. Recall: 0.627\n",
            "Epoch [6/15]. Loss: 0.100. Acc: 0.967 F1-score: 0.765. Test loss: 0.125. Test acc: 0.943. Test F1_score: 0.615. Recall: 0.652\n",
            "Epoch [7/15]. Loss: 0.083. Acc: 0.972 F1-score: 0.805. Test loss: 0.079. Test acc: 0.939. Test F1_score: 0.606. Recall: 0.665\n",
            "Epoch [8/15]. Loss: 0.058. Acc: 0.977 F1-score: 0.845. Test loss: 0.218. Test acc: 0.942. Test F1_score: 0.601. Recall: 0.623\n",
            "Epoch [9/15]. Loss: 0.046. Acc: 0.982 F1-score: 0.877. Test loss: 0.186. Test acc: 0.945. Test F1_score: 0.598. Recall: 0.580\n",
            "Epoch [10/15]. Loss: 0.050. Acc: 0.985 F1-score: 0.891. Test loss: 0.232. Test acc: 0.946. Test F1_score: 0.605. Recall: 0.587\n",
            "Epoch [11/15]. Loss: 0.049. Acc: 0.985 F1-score: 0.898. Test loss: 0.169. Test acc: 0.941. Test F1_score: 0.587. Recall: 0.603\n",
            "Epoch [12/15]. Loss: 0.025. Acc: 0.989 F1-score: 0.923. Test loss: 0.377. Test acc: 0.943. Test F1_score: 0.599. Recall: 0.609\n",
            "Epoch [13/15]. Loss: 0.032. Acc: 0.989 F1-score: 0.925. Test loss: 0.267. Test acc: 0.939. Test F1_score: 0.595. Recall: 0.638\n",
            "Epoch [14/15]. Loss: 0.034. Acc: 0.991 F1-score: 0.936. Test loss: 0.183. Test acc: 0.948. Test F1_score: 0.609. Recall: 0.576\n",
            "Epoch [15/15]. Loss: 0.017. Acc: 0.992 F1-score: 0.942. Test loss: 0.138. Test acc: 0.945. Test F1_score: 0.608. Recall: 0.605\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6076233183856502"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но вообще мы видим, что достаточно быстро можем наблюдать переобучение модели."
      ],
      "metadata": {
        "id": "hjHNyPeq9rAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "is1NrdPc-P19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, )\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "1Ghn6CEj-daM"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn_GRU(th=0.5, vocab_size=1500, embedding_dim=128, learning_rate=1e-3, epochs=epochs, batch_size=batch_size, visual=False):\n",
        "\n",
        "  random_state = 42\n",
        "\n",
        "  # max_words = 1500\n",
        "  max_len = 15\n",
        "  num_classes = 1\n",
        "\n",
        "  # Training\n",
        "  epochs = epochs\n",
        "  batch_size = batch_size\n",
        "  # embedding_dim = 256\n",
        "  # out_channel = 256\n",
        "\n",
        "  model_GRU = GRUFixedLen(vocab_size, embedding_dim)\n",
        "  optimizer = torch.optim.Adam(model_GRU.parameters(), lr=learning_rate)\n",
        "  criterion = nn.BCELoss()\n",
        "\n",
        "  print(\"Parameters of model:\", sum([param.nelement() for param in model_GRU.parameters()]))\n",
        "\n",
        "  model_GRU = model_GRU.to(device)\n",
        "  model_GRU.train()\n",
        "  th = th\n",
        "\n",
        "  train_loss_history = []\n",
        "  test_loss_history = []\n",
        "  train_f1_history = []\n",
        "  test_f1_history = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "  \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_GRU(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "\n",
        "        tp += ((labels == 1) & (pred_labels == 1)).sum().item()\n",
        "        tn += ((labels == 0) & (pred_labels == 0)).sum().item()\n",
        "        fp += ((labels == 0) & (pred_labels == 1)).sum().item()\n",
        "        fn += ((labels == 1) & (pred_labels == 0)).sum().item()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    model_GRU.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "          # f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "          f'Loss: {loss:.3f}. ' \\\n",
        "          f'Acc: {running_right / running_items:.3f}',\n",
        "          f'F1-score: {f1_score:.3f}', end='. ')\n",
        "    \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "    train_loss_history.append(loss)\n",
        "    train_f1_history.append(f1_score)\n",
        "    # print(train_f1_history)\n",
        "\n",
        "    # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    test_tp, test_fp, test_tn, test_fn = 0, 0, 0, 0\n",
        "\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = model_GRU(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "        test_tp += ((test_labels == 1) & (pred_test_labels == 1)).sum().item()\n",
        "        test_tn += ((test_labels == 0) & (pred_test_labels == 0)).sum().item()\n",
        "        test_fp += ((test_labels == 0) & (pred_test_labels == 1)).sum().item()\n",
        "        test_fn += ((test_labels == 1) & (pred_test_labels == 0)).sum().item()\n",
        "\n",
        "    test_precision = test_tp / (test_tp + test_fp) if (test_tp + test_fp) != 0 else 0\n",
        "    test_recall = test_tp / (test_tp + test_fn) if (test_tp + test_fn) != 0 else 0\n",
        "\n",
        "    test_f1_score = 2 * test_precision * test_recall / (test_precision + test_recall) if (test_precision + test_recall) != 0 else 0\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    test_f1_history.append(test_f1_score)\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}. Test F1_score: {test_f1_score:.3f}. Recall: {test_recall:.3f}')\n",
        "    \n",
        "    model_GRU.train()\n",
        "\n",
        "  if visual is True:\n",
        "   \n",
        "    plt.title('F1 history')\n",
        "    plt.grid(True)\n",
        "    plt.ylabel('F1 score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(train_f1_history, label='train')\n",
        "    plt.plot(test_f1_history, label='test')\n",
        "    plt.legend();\n",
        "        \n",
        "  print('Training is finished!')\n",
        "\n",
        "  return test_f1_history[-1]"
      ],
      "metadata": {
        "id": "PnpDP1mP-nLE"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_tab_gru = []\n",
        "epch_tab_gru = []\n",
        "lr_tab_gru = []\n",
        "thr_tab_gru = []\n",
        "emb_dim_tab_gru = []\n",
        "\n",
        "for epch in n_epochs:\n",
        "  for lr in learning_rates:\n",
        "    for thr in ths:\n",
        "      for e in e_dims:\n",
        "        print('\\033[1m' + f'Количество эпох: {epch} \\nШаг обучения: {lr}' + '\\033[0m')\n",
        "        epch_tab_gru.append(epch)\n",
        "        lr_tab_gru.append(lr)\n",
        "        thr_tab_gru.append(thr)\n",
        "        emb_dim_tab_gru.append(e)\n",
        "        f1_tab_gru.append(round(train_nn_GRU(learning_rate=lr, epochs=epch, th=thr, embedding_dim=e), 3))\n",
        "        print('-' * 50)\n",
        "        print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THLjusWq-9wy",
        "outputId": "3240bcbd-decd-4608-a9d6-4e112a3cc09d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/10]. Loss: 0.139. Acc: 0.917 F1-score: 0.331. Test loss: 0.120. Test acc: 0.949. Test F1_score: 0.508. Recall: 0.377\n",
            "Epoch [2/10]. Loss: 0.139. Acc: 0.949 F1-score: 0.609. Test loss: 0.113. Test acc: 0.944. Test F1_score: 0.594. Recall: 0.589\n",
            "Epoch [3/10]. Loss: 0.106. Acc: 0.955 F1-score: 0.674. Test loss: 0.129. Test acc: 0.947. Test F1_score: 0.615. Recall: 0.605\n",
            "Epoch [4/10]. Loss: 0.095. Acc: 0.961 F1-score: 0.718. Test loss: 0.125. Test acc: 0.941. Test F1_score: 0.596. Recall: 0.621\n",
            "Epoch [5/10]. Loss: 0.090. Acc: 0.965 F1-score: 0.753. Test loss: 0.181. Test acc: 0.938. Test F1_score: 0.582. Recall: 0.621\n",
            "Epoch [6/10]. Loss: 0.082. Acc: 0.969 F1-score: 0.781. Test loss: 0.171. Test acc: 0.940. Test F1_score: 0.598. Recall: 0.636\n",
            "Epoch [7/10]. Loss: 0.050. Acc: 0.971 F1-score: 0.800. Test loss: 0.204. Test acc: 0.950. Test F1_score: 0.629. Recall: 0.603\n",
            "Epoch [8/10]. Loss: 0.084. Acc: 0.975 F1-score: 0.827. Test loss: 0.238. Test acc: 0.949. Test F1_score: 0.622. Recall: 0.600\n",
            "Epoch [9/10]. Loss: 0.075. Acc: 0.977 F1-score: 0.841. Test loss: 0.116. Test acc: 0.949. Test F1_score: 0.607. Recall: 0.567\n",
            "Epoch [10/10]. Loss: 0.057. Acc: 0.978 F1-score: 0.847. Test loss: 0.222. Test acc: 0.942. Test F1_score: 0.600. Recall: 0.616\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/10]. Loss: 0.131. Acc: 0.920 F1-score: 0.409. Test loss: 0.152. Test acc: 0.943. Test F1_score: 0.579. Recall: 0.558\n",
            "Epoch [2/10]. Loss: 0.100. Acc: 0.952 F1-score: 0.641. Test loss: 0.171. Test acc: 0.952. Test F1_score: 0.592. Recall: 0.493\n",
            "Epoch [3/10]. Loss: 0.138. Acc: 0.958 F1-score: 0.698. Test loss: 0.126. Test acc: 0.945. Test F1_score: 0.596. Recall: 0.574\n",
            "Epoch [4/10]. Loss: 0.115. Acc: 0.963 F1-score: 0.743. Test loss: 0.209. Test acc: 0.944. Test F1_score: 0.603. Recall: 0.605\n",
            "Epoch [5/10]. Loss: 0.082. Acc: 0.968 F1-score: 0.781. Test loss: 0.127. Test acc: 0.945. Test F1_score: 0.600. Recall: 0.587\n",
            "Epoch [6/10]. Loss: 0.054. Acc: 0.973 F1-score: 0.812. Test loss: 0.145. Test acc: 0.941. Test F1_score: 0.591. Recall: 0.603\n",
            "Epoch [7/10]. Loss: 0.067. Acc: 0.975 F1-score: 0.829. Test loss: 0.159. Test acc: 0.940. Test F1_score: 0.573. Recall: 0.574\n",
            "Epoch [8/10]. Loss: 0.048. Acc: 0.978 F1-score: 0.844. Test loss: 0.321. Test acc: 0.941. Test F1_score: 0.582. Recall: 0.592\n",
            "Epoch [9/10]. Loss: 0.102. Acc: 0.979 F1-score: 0.853. Test loss: 0.309. Test acc: 0.945. Test F1_score: 0.602. Recall: 0.592\n",
            "Epoch [10/10]. Loss: 0.064. Acc: 0.982 F1-score: 0.873. Test loss: 0.227. Test acc: 0.937. Test F1_score: 0.580. Recall: 0.625\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/10]. Loss: 0.202. Acc: 0.922 F1-score: 0.301. Test loss: 0.115. Test acc: 0.946. Test F1_score: 0.508. Recall: 0.397\n",
            "Epoch [2/10]. Loss: 0.150. Acc: 0.952 F1-score: 0.570. Test loss: 0.084. Test acc: 0.951. Test F1_score: 0.547. Recall: 0.426\n",
            "Epoch [3/10]. Loss: 0.111. Acc: 0.959 F1-score: 0.653. Test loss: 0.128. Test acc: 0.952. Test F1_score: 0.559. Recall: 0.438\n",
            "Epoch [4/10]. Loss: 0.111. Acc: 0.963 F1-score: 0.695. Test loss: 0.069. Test acc: 0.951. Test F1_score: 0.601. Recall: 0.522\n",
            "Epoch [5/10]. Loss: 0.077. Acc: 0.968 F1-score: 0.743. Test loss: 0.172. Test acc: 0.952. Test F1_score: 0.589. Recall: 0.489\n",
            "Epoch [6/10]. Loss: 0.059. Acc: 0.973 F1-score: 0.788. Test loss: 0.105. Test acc: 0.952. Test F1_score: 0.595. Recall: 0.502\n",
            "Epoch [7/10]. Loss: 0.074. Acc: 0.976 F1-score: 0.814. Test loss: 0.066. Test acc: 0.953. Test F1_score: 0.609. Recall: 0.522\n",
            "Epoch [8/10]. Loss: 0.047. Acc: 0.977 F1-score: 0.825. Test loss: 0.149. Test acc: 0.954. Test F1_score: 0.607. Recall: 0.502\n",
            "Epoch [9/10]. Loss: 0.067. Acc: 0.977 F1-score: 0.828. Test loss: 0.173. Test acc: 0.952. Test F1_score: 0.609. Recall: 0.538\n",
            "Epoch [10/10]. Loss: 0.061. Acc: 0.982 F1-score: 0.865. Test loss: 0.185. Test acc: 0.952. Test F1_score: 0.615. Recall: 0.545\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/10]. Loss: 0.159. Acc: 0.940 F1-score: 0.382. Test loss: 0.133. Test acc: 0.953. Test F1_score: 0.548. Recall: 0.404\n",
            "Epoch [2/10]. Loss: 0.129. Acc: 0.955 F1-score: 0.605. Test loss: 0.140. Test acc: 0.953. Test F1_score: 0.579. Recall: 0.460\n",
            "Epoch [3/10]. Loss: 0.101. Acc: 0.963 F1-score: 0.684. Test loss: 0.184. Test acc: 0.950. Test F1_score: 0.591. Recall: 0.520\n",
            "Epoch [4/10]. Loss: 0.090. Acc: 0.966 F1-score: 0.727. Test loss: 0.107. Test acc: 0.953. Test F1_score: 0.623. Recall: 0.551\n",
            "Epoch [5/10]. Loss: 0.073. Acc: 0.970 F1-score: 0.768. Test loss: 0.132. Test acc: 0.955. Test F1_score: 0.624. Recall: 0.536\n",
            "Epoch [6/10]. Loss: 0.105. Acc: 0.974 F1-score: 0.797. Test loss: 0.103. Test acc: 0.951. Test F1_score: 0.611. Recall: 0.545\n",
            "Epoch [7/10]. Loss: 0.071. Acc: 0.979 F1-score: 0.837. Test loss: 0.134. Test acc: 0.951. Test F1_score: 0.617. Recall: 0.567\n",
            "Epoch [8/10]. Loss: 0.069. Acc: 0.980 F1-score: 0.848. Test loss: 0.146. Test acc: 0.951. Test F1_score: 0.604. Recall: 0.529\n",
            "Epoch [9/10]. Loss: 0.066. Acc: 0.981 F1-score: 0.857. Test loss: 0.255. Test acc: 0.947. Test F1_score: 0.600. Recall: 0.565\n",
            "Epoch [10/10]. Loss: 0.103. Acc: 0.982 F1-score: 0.868. Test loss: 0.126. Test acc: 0.951. Test F1_score: 0.619. Recall: 0.565\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/10]. Loss: 0.195. Acc: 0.811 F1-score: 0.112. Test loss: 0.180. Test acc: 0.934. Test F1_score: 0.172. Recall: 0.098\n",
            "Epoch [2/10]. Loss: 0.173. Acc: 0.933 F1-score: 0.396. Test loss: 0.183. Test acc: 0.943. Test F1_score: 0.503. Recall: 0.415\n",
            "Epoch [3/10]. Loss: 0.159. Acc: 0.943 F1-score: 0.560. Test loss: 0.120. Test acc: 0.947. Test F1_score: 0.570. Recall: 0.502\n",
            "Epoch [4/10]. Loss: 0.125. Acc: 0.947 F1-score: 0.595. Test loss: 0.091. Test acc: 0.946. Test F1_score: 0.600. Recall: 0.578\n",
            "Epoch [5/10]. Loss: 0.133. Acc: 0.951 F1-score: 0.645. Test loss: 0.085. Test acc: 0.951. Test F1_score: 0.609. Recall: 0.549\n",
            "Epoch [6/10]. Loss: 0.110. Acc: 0.955 F1-score: 0.673. Test loss: 0.167. Test acc: 0.940. Test F1_score: 0.597. Recall: 0.636\n",
            "Epoch [7/10]. Loss: 0.149. Acc: 0.957 F1-score: 0.694. Test loss: 0.111. Test acc: 0.942. Test F1_score: 0.605. Recall: 0.632\n",
            "Epoch [8/10]. Loss: 0.099. Acc: 0.959 F1-score: 0.716. Test loss: 0.138. Test acc: 0.948. Test F1_score: 0.610. Recall: 0.578\n",
            "Epoch [9/10]. Loss: 0.063. Acc: 0.963 F1-score: 0.741. Test loss: 0.187. Test acc: 0.942. Test F1_score: 0.608. Recall: 0.643\n",
            "Epoch [10/10]. Loss: 0.098. Acc: 0.964 F1-score: 0.749. Test loss: 0.198. Test acc: 0.949. Test F1_score: 0.607. Recall: 0.562\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/10]. Loss: 0.178. Acc: 0.797 F1-score: 0.136. Test loss: 0.173. Test acc: 0.935. Test F1_score: 0.426. Recall: 0.344\n",
            "Epoch [2/10]. Loss: 0.188. Acc: 0.941 F1-score: 0.518. Test loss: 0.130. Test acc: 0.944. Test F1_score: 0.575. Recall: 0.538\n",
            "Epoch [3/10]. Loss: 0.107. Acc: 0.948 F1-score: 0.615. Test loss: 0.137. Test acc: 0.942. Test F1_score: 0.598. Recall: 0.614\n",
            "Epoch [4/10]. Loss: 0.120. Acc: 0.952 F1-score: 0.656. Test loss: 0.125. Test acc: 0.945. Test F1_score: 0.601. Recall: 0.589\n",
            "Epoch [5/10]. Loss: 0.103. Acc: 0.956 F1-score: 0.688. Test loss: 0.116. Test acc: 0.948. Test F1_score: 0.617. Recall: 0.596\n",
            "Epoch [6/10]. Loss: 0.085. Acc: 0.960 F1-score: 0.718. Test loss: 0.173. Test acc: 0.943. Test F1_score: 0.600. Recall: 0.607\n",
            "Epoch [7/10]. Loss: 0.110. Acc: 0.963 F1-score: 0.742. Test loss: 0.088. Test acc: 0.948. Test F1_score: 0.600. Recall: 0.560\n",
            "Epoch [8/10]. Loss: 0.055. Acc: 0.967 F1-score: 0.770. Test loss: 0.124. Test acc: 0.949. Test F1_score: 0.605. Recall: 0.558\n",
            "Epoch [9/10]. Loss: 0.065. Acc: 0.972 F1-score: 0.808. Test loss: 0.159. Test acc: 0.949. Test F1_score: 0.620. Recall: 0.587\n",
            "Epoch [10/10]. Loss: 0.046. Acc: 0.976 F1-score: 0.834. Test loss: 0.157. Test acc: 0.941. Test F1_score: 0.579. Recall: 0.578\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/10]. Loss: 0.216. Acc: 0.913 F1-score: 0.052. Test loss: 0.176. Test acc: 0.933. Test F1_score: 0.177. Recall: 0.103\n",
            "Epoch [2/10]. Loss: 0.206. Acc: 0.941 F1-score: 0.396. Test loss: 0.204. Test acc: 0.945. Test F1_score: 0.483. Recall: 0.366\n",
            "Epoch [3/10]. Loss: 0.141. Acc: 0.949 F1-score: 0.527. Test loss: 0.180. Test acc: 0.947. Test F1_score: 0.550. Recall: 0.460\n",
            "Epoch [4/10]. Loss: 0.090. Acc: 0.954 F1-score: 0.594. Test loss: 0.110. Test acc: 0.953. Test F1_score: 0.557. Recall: 0.424\n",
            "Epoch [5/10]. Loss: 0.110. Acc: 0.956 F1-score: 0.625. Test loss: 0.128. Test acc: 0.952. Test F1_score: 0.594. Recall: 0.496\n",
            "Epoch [6/10]. Loss: 0.120. Acc: 0.958 F1-score: 0.647. Test loss: 0.155. Test acc: 0.953. Test F1_score: 0.578. Recall: 0.455\n",
            "Epoch [7/10]. Loss: 0.093. Acc: 0.961 F1-score: 0.674. Test loss: 0.130. Test acc: 0.954. Test F1_score: 0.585. Recall: 0.462\n",
            "Epoch [8/10]. Loss: 0.087. Acc: 0.965 F1-score: 0.714. Test loss: 0.175. Test acc: 0.950. Test F1_score: 0.608. Recall: 0.551\n",
            "Epoch [9/10]. Loss: 0.046. Acc: 0.965 F1-score: 0.722. Test loss: 0.182. Test acc: 0.954. Test F1_score: 0.593. Recall: 0.480\n",
            "Epoch [10/10]. Loss: 0.097. Acc: 0.969 F1-score: 0.750. Test loss: 0.150. Test acc: 0.951. Test F1_score: 0.606. Recall: 0.538\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 10 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/10]. Loss: 0.168. Acc: 0.900 F1-score: 0.094. Test loss: 0.222. Test acc: 0.941. Test F1_score: 0.423. Recall: 0.310\n",
            "Epoch [2/10]. Loss: 0.127. Acc: 0.946 F1-score: 0.499. Test loss: 0.143. Test acc: 0.950. Test F1_score: 0.569. Recall: 0.469\n",
            "Epoch [3/10]. Loss: 0.126. Acc: 0.954 F1-score: 0.594. Test loss: 0.121. Test acc: 0.951. Test F1_score: 0.569. Recall: 0.467\n",
            "Epoch [4/10]. Loss: 0.102. Acc: 0.958 F1-score: 0.639. Test loss: 0.183. Test acc: 0.953. Test F1_score: 0.602. Recall: 0.502\n",
            "Epoch [5/10]. Loss: 0.116. Acc: 0.961 F1-score: 0.671. Test loss: 0.228. Test acc: 0.952. Test F1_score: 0.606. Recall: 0.527\n",
            "Epoch [6/10]. Loss: 0.092. Acc: 0.963 F1-score: 0.693. Test loss: 0.179. Test acc: 0.952. Test F1_score: 0.603. Recall: 0.525\n",
            "Epoch [7/10]. Loss: 0.109. Acc: 0.968 F1-score: 0.745. Test loss: 0.184. Test acc: 0.952. Test F1_score: 0.585. Recall: 0.484\n",
            "Epoch [8/10]. Loss: 0.064. Acc: 0.971 F1-score: 0.767. Test loss: 0.145. Test acc: 0.949. Test F1_score: 0.613. Recall: 0.574\n",
            "Epoch [9/10]. Loss: 0.049. Acc: 0.975 F1-score: 0.804. Test loss: 0.184. Test acc: 0.951. Test F1_score: 0.621. Recall: 0.571\n",
            "Epoch [10/10]. Loss: 0.057. Acc: 0.977 F1-score: 0.821. Test loss: 0.212. Test acc: 0.951. Test F1_score: 0.611. Recall: 0.551\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/15]. Loss: 0.183. Acc: 0.915 F1-score: 0.311. Test loss: 0.122. Test acc: 0.942. Test F1_score: 0.483. Recall: 0.384\n",
            "Epoch [2/15]. Loss: 0.127. Acc: 0.947 F1-score: 0.605. Test loss: 0.162. Test acc: 0.940. Test F1_score: 0.591. Recall: 0.614\n",
            "Epoch [3/15]. Loss: 0.115. Acc: 0.954 F1-score: 0.672. Test loss: 0.152. Test acc: 0.941. Test F1_score: 0.583. Recall: 0.592\n",
            "Epoch [4/15]. Loss: 0.099. Acc: 0.961 F1-score: 0.730. Test loss: 0.169. Test acc: 0.949. Test F1_score: 0.612. Recall: 0.580\n",
            "Epoch [5/15]. Loss: 0.068. Acc: 0.964 F1-score: 0.754. Test loss: 0.116. Test acc: 0.940. Test F1_score: 0.603. Recall: 0.645\n",
            "Epoch [6/15]. Loss: 0.086. Acc: 0.969 F1-score: 0.789. Test loss: 0.101. Test acc: 0.940. Test F1_score: 0.569. Recall: 0.565\n",
            "Epoch [7/15]. Loss: 0.060. Acc: 0.973 F1-score: 0.818. Test loss: 0.115. Test acc: 0.941. Test F1_score: 0.595. Recall: 0.614\n",
            "Epoch [8/15]. Loss: 0.058. Acc: 0.975 F1-score: 0.830. Test loss: 0.166. Test acc: 0.939. Test F1_score: 0.583. Recall: 0.612\n",
            "Epoch [9/15]. Loss: 0.078. Acc: 0.977 F1-score: 0.839. Test loss: 0.243. Test acc: 0.934. Test F1_score: 0.560. Recall: 0.600\n",
            "Epoch [10/15]. Loss: 0.069. Acc: 0.979 F1-score: 0.851. Test loss: 0.249. Test acc: 0.938. Test F1_score: 0.571. Recall: 0.592\n",
            "Epoch [11/15]. Loss: 0.063. Acc: 0.977 F1-score: 0.843. Test loss: 0.182. Test acc: 0.936. Test F1_score: 0.579. Recall: 0.623\n",
            "Epoch [12/15]. Loss: 0.049. Acc: 0.981 F1-score: 0.870. Test loss: 0.164. Test acc: 0.939. Test F1_score: 0.579. Recall: 0.596\n",
            "Epoch [13/15]. Loss: 0.048. Acc: 0.980 F1-score: 0.864. Test loss: 0.170. Test acc: 0.942. Test F1_score: 0.579. Recall: 0.571\n",
            "Epoch [14/15]. Loss: 0.039. Acc: 0.981 F1-score: 0.869. Test loss: 0.188. Test acc: 0.937. Test F1_score: 0.567. Recall: 0.589\n",
            "Epoch [15/15]. Loss: 0.070. Acc: 0.982 F1-score: 0.877. Test loss: 0.148. Test acc: 0.937. Test F1_score: 0.560. Recall: 0.569\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/15]. Loss: 0.157. Acc: 0.917 F1-score: 0.406. Test loss: 0.116. Test acc: 0.949. Test F1_score: 0.595. Recall: 0.540\n",
            "Epoch [2/15]. Loss: 0.133. Acc: 0.953 F1-score: 0.647. Test loss: 0.156. Test acc: 0.945. Test F1_score: 0.613. Recall: 0.623\n",
            "Epoch [3/15]. Loss: 0.102. Acc: 0.958 F1-score: 0.700. Test loss: 0.211. Test acc: 0.940. Test F1_score: 0.596. Recall: 0.632\n",
            "Epoch [4/15]. Loss: 0.060. Acc: 0.965 F1-score: 0.752. Test loss: 0.126. Test acc: 0.952. Test F1_score: 0.636. Recall: 0.598\n",
            "Epoch [5/15]. Loss: 0.066. Acc: 0.968 F1-score: 0.781. Test loss: 0.094. Test acc: 0.947. Test F1_score: 0.612. Recall: 0.594\n",
            "Epoch [6/15]. Loss: 0.081. Acc: 0.974 F1-score: 0.816. Test loss: 0.077. Test acc: 0.930. Test F1_score: 0.555. Recall: 0.623\n",
            "Epoch [7/15]. Loss: 0.049. Acc: 0.975 F1-score: 0.825. Test loss: 0.151. Test acc: 0.945. Test F1_score: 0.598. Recall: 0.580\n",
            "Epoch [8/15]. Loss: 0.047. Acc: 0.979 F1-score: 0.853. Test loss: 0.139. Test acc: 0.939. Test F1_score: 0.578. Recall: 0.594\n",
            "Epoch [9/15]. Loss: 0.085. Acc: 0.980 F1-score: 0.859. Test loss: 0.245. Test acc: 0.941. Test F1_score: 0.581. Recall: 0.589\n",
            "Epoch [10/15]. Loss: 0.072. Acc: 0.981 F1-score: 0.868. Test loss: 0.179. Test acc: 0.939. Test F1_score: 0.571. Recall: 0.585\n",
            "Epoch [11/15]. Loss: 0.027. Acc: 0.983 F1-score: 0.883. Test loss: 0.160. Test acc: 0.944. Test F1_score: 0.606. Recall: 0.612\n",
            "Epoch [12/15]. Loss: 0.038. Acc: 0.983 F1-score: 0.881. Test loss: 0.207. Test acc: 0.942. Test F1_score: 0.581. Recall: 0.574\n",
            "Epoch [13/15]. Loss: 0.050. Acc: 0.985 F1-score: 0.892. Test loss: 0.365. Test acc: 0.941. Test F1_score: 0.577. Recall: 0.571\n",
            "Epoch [14/15]. Loss: 0.042. Acc: 0.984 F1-score: 0.890. Test loss: 0.342. Test acc: 0.942. Test F1_score: 0.582. Recall: 0.576\n",
            "Epoch [15/15]. Loss: 0.039. Acc: 0.985 F1-score: 0.894. Test loss: 0.150. Test acc: 0.938. Test F1_score: 0.571. Recall: 0.589\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/15]. Loss: 0.170. Acc: 0.919 F1-score: 0.263. Test loss: 0.129. Test acc: 0.949. Test F1_score: 0.483. Recall: 0.342\n",
            "Epoch [2/15]. Loss: 0.133. Acc: 0.953 F1-score: 0.578. Test loss: 0.148. Test acc: 0.952. Test F1_score: 0.592. Recall: 0.502\n",
            "Epoch [3/15]. Loss: 0.145. Acc: 0.960 F1-score: 0.663. Test loss: 0.117. Test acc: 0.951. Test F1_score: 0.610. Recall: 0.545\n",
            "Epoch [4/15]. Loss: 0.088. Acc: 0.966 F1-score: 0.726. Test loss: 0.159. Test acc: 0.953. Test F1_score: 0.595. Recall: 0.496\n",
            "Epoch [5/15]. Loss: 0.073. Acc: 0.970 F1-score: 0.764. Test loss: 0.183. Test acc: 0.950. Test F1_score: 0.601. Recall: 0.533\n",
            "Epoch [6/15]. Loss: 0.055. Acc: 0.974 F1-score: 0.799. Test loss: 0.227. Test acc: 0.952. Test F1_score: 0.621. Recall: 0.562\n",
            "Epoch [7/15]. Loss: 0.083. Acc: 0.976 F1-score: 0.816. Test loss: 0.268. Test acc: 0.948. Test F1_score: 0.610. Recall: 0.583\n",
            "Epoch [8/15]. Loss: 0.075. Acc: 0.978 F1-score: 0.832. Test loss: 0.170. Test acc: 0.948. Test F1_score: 0.618. Recall: 0.598\n",
            "Epoch [9/15]. Loss: 0.073. Acc: 0.978 F1-score: 0.837. Test loss: 0.263. Test acc: 0.948. Test F1_score: 0.600. Recall: 0.558\n",
            "Epoch [10/15]. Loss: 0.044. Acc: 0.980 F1-score: 0.850. Test loss: 0.275. Test acc: 0.947. Test F1_score: 0.604. Recall: 0.580\n",
            "Epoch [11/15]. Loss: 0.062. Acc: 0.983 F1-score: 0.874. Test loss: 0.174. Test acc: 0.948. Test F1_score: 0.606. Recall: 0.571\n",
            "Epoch [12/15]. Loss: 0.073. Acc: 0.982 F1-score: 0.865. Test loss: 0.299. Test acc: 0.947. Test F1_score: 0.597. Recall: 0.562\n",
            "Epoch [13/15]. Loss: 0.027. Acc: 0.984 F1-score: 0.881. Test loss: 0.126. Test acc: 0.949. Test F1_score: 0.602. Recall: 0.554\n",
            "Epoch [14/15]. Loss: 0.047. Acc: 0.984 F1-score: 0.883. Test loss: 0.355. Test acc: 0.946. Test F1_score: 0.591. Recall: 0.556\n",
            "Epoch [15/15]. Loss: 0.058. Acc: 0.984 F1-score: 0.884. Test loss: 0.245. Test acc: 0.945. Test F1_score: 0.588. Recall: 0.562\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.01\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/15]. Loss: 0.169. Acc: 0.922 F1-score: 0.331. Test loss: 0.120. Test acc: 0.946. Test F1_score: 0.577. Recall: 0.529\n",
            "Epoch [2/15]. Loss: 0.107. Acc: 0.956 F1-score: 0.621. Test loss: 0.131. Test acc: 0.952. Test F1_score: 0.610. Recall: 0.533\n",
            "Epoch [3/15]. Loss: 0.111. Acc: 0.964 F1-score: 0.697. Test loss: 0.249. Test acc: 0.951. Test F1_score: 0.595. Recall: 0.509\n",
            "Epoch [4/15]. Loss: 0.109. Acc: 0.968 F1-score: 0.744. Test loss: 0.206. Test acc: 0.952. Test F1_score: 0.593. Recall: 0.504\n",
            "Epoch [5/15]. Loss: 0.063. Acc: 0.972 F1-score: 0.783. Test loss: 0.139. Test acc: 0.950. Test F1_score: 0.596. Recall: 0.527\n",
            "Epoch [6/15]. Loss: 0.058. Acc: 0.976 F1-score: 0.815. Test loss: 0.100. Test acc: 0.950. Test F1_score: 0.599. Recall: 0.531\n",
            "Epoch [7/15]. Loss: 0.072. Acc: 0.979 F1-score: 0.839. Test loss: 0.260. Test acc: 0.947. Test F1_score: 0.587. Recall: 0.542\n",
            "Epoch [8/15]. Loss: 0.053. Acc: 0.981 F1-score: 0.855. Test loss: 0.174. Test acc: 0.948. Test F1_score: 0.603. Recall: 0.560\n",
            "Epoch [9/15]. Loss: 0.042. Acc: 0.983 F1-score: 0.871. Test loss: 0.162. Test acc: 0.943. Test F1_score: 0.579. Recall: 0.562\n",
            "Epoch [10/15]. Loss: 0.062. Acc: 0.983 F1-score: 0.875. Test loss: 0.436. Test acc: 0.949. Test F1_score: 0.585. Recall: 0.516\n",
            "Epoch [11/15]. Loss: 0.049. Acc: 0.984 F1-score: 0.882. Test loss: 0.275. Test acc: 0.947. Test F1_score: 0.603. Recall: 0.574\n",
            "Epoch [12/15]. Loss: 0.039. Acc: 0.984 F1-score: 0.878. Test loss: 0.254. Test acc: 0.947. Test F1_score: 0.601. Recall: 0.565\n",
            "Epoch [13/15]. Loss: 0.032. Acc: 0.985 F1-score: 0.886. Test loss: 0.201. Test acc: 0.947. Test F1_score: 0.597. Recall: 0.560\n",
            "Epoch [14/15]. Loss: 0.026. Acc: 0.986 F1-score: 0.897. Test loss: 0.204. Test acc: 0.949. Test F1_score: 0.598. Recall: 0.540\n",
            "Epoch [15/15]. Loss: 0.054. Acc: 0.986 F1-score: 0.898. Test loss: 0.160. Test acc: 0.947. Test F1_score: 0.598. Recall: 0.558\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/15]. Loss: 0.192. Acc: 0.793 F1-score: 0.109. Test loss: 0.247. Test acc: 0.933. Test F1_score: 0.259. Recall: 0.167\n",
            "Epoch [2/15]. Loss: 0.168. Acc: 0.936 F1-score: 0.442. Test loss: 0.189. Test acc: 0.938. Test F1_score: 0.501. Recall: 0.446\n",
            "Epoch [3/15]. Loss: 0.184. Acc: 0.943 F1-score: 0.560. Test loss: 0.152. Test acc: 0.947. Test F1_score: 0.566. Recall: 0.491\n",
            "Epoch [4/15]. Loss: 0.130. Acc: 0.948 F1-score: 0.613. Test loss: 0.165. Test acc: 0.948. Test F1_score: 0.605. Recall: 0.565\n",
            "Epoch [5/15]. Loss: 0.144. Acc: 0.951 F1-score: 0.644. Test loss: 0.153. Test acc: 0.944. Test F1_score: 0.610. Recall: 0.625\n",
            "Epoch [6/15]. Loss: 0.129. Acc: 0.953 F1-score: 0.668. Test loss: 0.209. Test acc: 0.948. Test F1_score: 0.622. Recall: 0.612\n",
            "Epoch [7/15]. Loss: 0.095. Acc: 0.957 F1-score: 0.694. Test loss: 0.126. Test acc: 0.946. Test F1_score: 0.621. Recall: 0.627\n",
            "Epoch [8/15]. Loss: 0.106. Acc: 0.959 F1-score: 0.708. Test loss: 0.162. Test acc: 0.935. Test F1_score: 0.587. Recall: 0.658\n",
            "Epoch [9/15]. Loss: 0.114. Acc: 0.961 F1-score: 0.728. Test loss: 0.105. Test acc: 0.944. Test F1_score: 0.609. Recall: 0.621\n",
            "Epoch [10/15]. Loss: 0.096. Acc: 0.965 F1-score: 0.752. Test loss: 0.098. Test acc: 0.947. Test F1_score: 0.623. Recall: 0.621\n",
            "Epoch [11/15]. Loss: 0.073. Acc: 0.968 F1-score: 0.779. Test loss: 0.180. Test acc: 0.943. Test F1_score: 0.613. Recall: 0.643\n",
            "Epoch [12/15]. Loss: 0.074. Acc: 0.968 F1-score: 0.782. Test loss: 0.220. Test acc: 0.942. Test F1_score: 0.598. Recall: 0.621\n",
            "Epoch [13/15]. Loss: 0.085. Acc: 0.970 F1-score: 0.795. Test loss: 0.200. Test acc: 0.950. Test F1_score: 0.619. Recall: 0.580\n",
            "Epoch [14/15]. Loss: 0.095. Acc: 0.975 F1-score: 0.824. Test loss: 0.175. Test acc: 0.947. Test F1_score: 0.616. Recall: 0.612\n",
            "Epoch [15/15]. Loss: 0.072. Acc: 0.977 F1-score: 0.839. Test loss: 0.171. Test acc: 0.942. Test F1_score: 0.601. Recall: 0.627\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/15]. Loss: 0.180. Acc: 0.797 F1-score: 0.138. Test loss: 0.170. Test acc: 0.937. Test F1_score: 0.458. Recall: 0.377\n",
            "Epoch [2/15]. Loss: 0.170. Acc: 0.940 F1-score: 0.519. Test loss: 0.125. Test acc: 0.946. Test F1_score: 0.577. Recall: 0.529\n",
            "Epoch [3/15]. Loss: 0.150. Acc: 0.949 F1-score: 0.622. Test loss: 0.140. Test acc: 0.945. Test F1_score: 0.604. Recall: 0.603\n",
            "Epoch [4/15]. Loss: 0.104. Acc: 0.954 F1-score: 0.666. Test loss: 0.116. Test acc: 0.948. Test F1_score: 0.618. Recall: 0.603\n",
            "Epoch [5/15]. Loss: 0.111. Acc: 0.957 F1-score: 0.693. Test loss: 0.190. Test acc: 0.943. Test F1_score: 0.609. Recall: 0.638\n",
            "Epoch [6/15]. Loss: 0.139. Acc: 0.960 F1-score: 0.717. Test loss: 0.167. Test acc: 0.941. Test F1_score: 0.597. Recall: 0.627\n",
            "Epoch [7/15]. Loss: 0.119. Acc: 0.964 F1-score: 0.744. Test loss: 0.164. Test acc: 0.940. Test F1_score: 0.590. Recall: 0.616\n",
            "Epoch [8/15]. Loss: 0.088. Acc: 0.967 F1-score: 0.772. Test loss: 0.168. Test acc: 0.936. Test F1_score: 0.572. Recall: 0.609\n",
            "Epoch [9/15]. Loss: 0.092. Acc: 0.972 F1-score: 0.801. Test loss: 0.157. Test acc: 0.939. Test F1_score: 0.596. Recall: 0.636\n",
            "Epoch [10/15]. Loss: 0.071. Acc: 0.974 F1-score: 0.818. Test loss: 0.233. Test acc: 0.943. Test F1_score: 0.595. Recall: 0.596\n",
            "Epoch [11/15]. Loss: 0.039. Acc: 0.977 F1-score: 0.838. Test loss: 0.185. Test acc: 0.941. Test F1_score: 0.599. Recall: 0.629\n",
            "Epoch [12/15]. Loss: 0.059. Acc: 0.980 F1-score: 0.860. Test loss: 0.221. Test acc: 0.935. Test F1_score: 0.576. Recall: 0.625\n",
            "Epoch [13/15]. Loss: 0.050. Acc: 0.982 F1-score: 0.873. Test loss: 0.396. Test acc: 0.943. Test F1_score: 0.602. Recall: 0.618\n",
            "Epoch [14/15]. Loss: 0.049. Acc: 0.981 F1-score: 0.870. Test loss: 0.197. Test acc: 0.947. Test F1_score: 0.611. Recall: 0.592\n",
            "Epoch [15/15]. Loss: 0.035. Acc: 0.984 F1-score: 0.890. Test loss: 0.235. Test acc: 0.943. Test F1_score: 0.597. Recall: 0.603\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 390273\n",
            "Epoch [1/15]. Loss: 0.267. Acc: 0.912 F1-score: 0.049. Test loss: 0.240. Test acc: 0.931. Test F1_score: 0.200. Recall: 0.123\n",
            "Epoch [2/15]. Loss: 0.193. Acc: 0.942 F1-score: 0.406. Test loss: 0.165. Test acc: 0.946. Test F1_score: 0.525. Recall: 0.424\n",
            "Epoch [3/15]. Loss: 0.152. Acc: 0.949 F1-score: 0.525. Test loss: 0.173. Test acc: 0.951. Test F1_score: 0.563. Recall: 0.451\n",
            "Epoch [4/15]. Loss: 0.159. Acc: 0.953 F1-score: 0.577. Test loss: 0.144. Test acc: 0.951. Test F1_score: 0.573. Recall: 0.467\n",
            "Epoch [5/15]. Loss: 0.121. Acc: 0.956 F1-score: 0.612. Test loss: 0.196. Test acc: 0.953. Test F1_score: 0.573. Recall: 0.453\n",
            "Epoch [6/15]. Loss: 0.104. Acc: 0.959 F1-score: 0.650. Test loss: 0.160. Test acc: 0.949. Test F1_score: 0.596. Recall: 0.536\n",
            "Epoch [7/15]. Loss: 0.089. Acc: 0.960 F1-score: 0.662. Test loss: 0.135. Test acc: 0.951. Test F1_score: 0.585. Recall: 0.496\n",
            "Epoch [8/15]. Loss: 0.121. Acc: 0.963 F1-score: 0.697. Test loss: 0.108. Test acc: 0.947. Test F1_score: 0.609. Recall: 0.585\n",
            "Epoch [9/15]. Loss: 0.150. Acc: 0.966 F1-score: 0.720. Test loss: 0.164. Test acc: 0.950. Test F1_score: 0.594. Recall: 0.527\n",
            "Epoch [10/15]. Loss: 0.108. Acc: 0.968 F1-score: 0.741. Test loss: 0.220. Test acc: 0.947. Test F1_score: 0.589. Recall: 0.542\n",
            "Epoch [11/15]. Loss: 0.106. Acc: 0.969 F1-score: 0.753. Test loss: 0.091. Test acc: 0.947. Test F1_score: 0.598. Recall: 0.558\n",
            "Epoch [12/15]. Loss: 0.079. Acc: 0.974 F1-score: 0.793. Test loss: 0.162. Test acc: 0.943. Test F1_score: 0.578. Recall: 0.560\n",
            "Epoch [13/15]. Loss: 0.054. Acc: 0.974 F1-score: 0.795. Test loss: 0.228. Test acc: 0.950. Test F1_score: 0.604. Recall: 0.542\n",
            "Epoch [14/15]. Loss: 0.044. Acc: 0.977 F1-score: 0.820. Test loss: 0.148. Test acc: 0.951. Test F1_score: 0.622. Recall: 0.576\n",
            "Epoch [15/15]. Loss: 0.071. Acc: 0.980 F1-score: 0.848. Test loss: 0.150. Test acc: 0.948. Test F1_score: 0.618. Recall: 0.600\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1mКоличество эпох: 15 \n",
            "Шаг обучения: 0.001\u001b[0m\n",
            "Parameters of model: 631425\n",
            "Epoch [1/15]. Loss: 0.167. Acc: 0.932 F1-score: 0.073. Test loss: 0.236. Test acc: 0.938. Test F1_score: 0.451. Recall: 0.362\n",
            "Epoch [2/15]. Loss: 0.125. Acc: 0.945 F1-score: 0.483. Test loss: 0.135. Test acc: 0.950. Test F1_score: 0.545. Recall: 0.429\n",
            "Epoch [3/15]. Loss: 0.115. Acc: 0.954 F1-score: 0.598. Test loss: 0.107. Test acc: 0.947. Test F1_score: 0.585. Recall: 0.531\n",
            "Epoch [4/15]. Loss: 0.133. Acc: 0.958 F1-score: 0.640. Test loss: 0.140. Test acc: 0.951. Test F1_score: 0.599. Recall: 0.527\n",
            "Epoch [5/15]. Loss: 0.112. Acc: 0.961 F1-score: 0.682. Test loss: 0.119. Test acc: 0.948. Test F1_score: 0.587. Recall: 0.527\n",
            "Epoch [6/15]. Loss: 0.109. Acc: 0.964 F1-score: 0.713. Test loss: 0.096. Test acc: 0.951. Test F1_score: 0.596. Recall: 0.511\n",
            "Epoch [7/15]. Loss: 0.087. Acc: 0.968 F1-score: 0.744. Test loss: 0.172. Test acc: 0.951. Test F1_score: 0.609. Recall: 0.547\n",
            "Epoch [8/15]. Loss: 0.063. Acc: 0.972 F1-score: 0.784. Test loss: 0.144. Test acc: 0.952. Test F1_score: 0.610. Recall: 0.533\n",
            "Epoch [9/15]. Loss: 0.098. Acc: 0.976 F1-score: 0.810. Test loss: 0.208. Test acc: 0.949. Test F1_score: 0.610. Recall: 0.569\n",
            "Epoch [10/15]. Loss: 0.093. Acc: 0.978 F1-score: 0.835. Test loss: 0.115. Test acc: 0.948. Test F1_score: 0.608. Recall: 0.576\n",
            "Epoch [11/15]. Loss: 0.057. Acc: 0.980 F1-score: 0.853. Test loss: 0.143. Test acc: 0.947. Test F1_score: 0.601. Recall: 0.576\n",
            "Epoch [12/15]. Loss: 0.060. Acc: 0.983 F1-score: 0.871. Test loss: 0.223. Test acc: 0.947. Test F1_score: 0.597. Recall: 0.562\n",
            "Epoch [13/15]. Loss: 0.049. Acc: 0.985 F1-score: 0.889. Test loss: 0.224. Test acc: 0.947. Test F1_score: 0.606. Recall: 0.583\n",
            "Epoch [14/15]. Loss: 0.017. Acc: 0.987 F1-score: 0.901. Test loss: 0.227. Test acc: 0.950. Test F1_score: 0.618. Recall: 0.576\n",
            "Epoch [15/15]. Loss: 0.058. Acc: 0.986 F1-score: 0.896. Test loss: 0.224. Test acc: 0.942. Test F1_score: 0.587. Recall: 0.592\n",
            "Training is finished!\n",
            "--------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_tab_GRU = pd.DataFrame({'epoch': epch_tab_gru,\n",
        "                            'lr': lr_tab_gru, 'th': thr_tab_gru, 'emb_dim': emb_dim_tab_gru,\n",
        "                            'test_f1_score': f1_tab_gru})\n",
        "metrics_tab_GRU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "PUHSHdD6_SLk",
        "outputId": "35842f9a-749f-4daf-89f3-428b672e87de"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch     lr   th  emb_dim  test_f1_score\n",
              "0      10  0.010  0.3      128          0.600\n",
              "1      10  0.010  0.3      256          0.580\n",
              "2      10  0.010  0.5      128          0.615\n",
              "3      10  0.010  0.5      256          0.619\n",
              "4      10  0.001  0.3      128          0.607\n",
              "5      10  0.001  0.3      256          0.579\n",
              "6      10  0.001  0.5      128          0.606\n",
              "7      10  0.001  0.5      256          0.611\n",
              "8      15  0.010  0.3      128          0.560\n",
              "9      15  0.010  0.3      256          0.571\n",
              "10     15  0.010  0.5      128          0.588\n",
              "11     15  0.010  0.5      256          0.598\n",
              "12     15  0.001  0.3      128          0.601\n",
              "13     15  0.001  0.3      256          0.597\n",
              "14     15  0.001  0.5      128          0.618\n",
              "15     15  0.001  0.5      256          0.587"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4afdd0d6-becf-4b77-9253-78a2c9872fc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>th</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>test_f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0.601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>256</td>\n",
              "      <td>0.597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4afdd0d6-becf-4b77-9253-78a2c9872fc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4afdd0d6-becf-4b77-9253-78a2c9872fc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4afdd0d6-becf-4b77-9253-78a2c9872fc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_tab_GRU.loc[metrics_tab_GRU['test_f1_score'] == metrics_tab_GRU['test_f1_score'].max()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "zpibqOPgAfP-",
        "outputId": "583ac750-8403-4eb2-e179-8745b834f39b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch    lr   th  emb_dim  test_f1_score\n",
              "3     10  0.01  0.5      256          0.619"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1608061c-55fc-4c81-b7bd-9147bc54eea0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>th</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>test_f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1608061c-55fc-4c81-b7bd-9147bc54eea0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1608061c-55fc-4c81-b7bd-9147bc54eea0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1608061c-55fc-4c81-b7bd-9147bc54eea0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В отличии от LSTM шаг обучения потребовался больше, также порог срабатывания = 0.5"
      ],
      "metadata": {
        "id": "QwY0C577Bu2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лучшая модель по GRU"
      ],
      "metadata": {
        "id": "A1-YGbzsAo_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_nn_GRU(epochs=10, learning_rate=0.01, embedding_dim=256, th=0.5, visual=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "aP8AKMCNAru_",
        "outputId": "c970970b-8893-47e6-f4dd-9506ca788490"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of model: 631425\n",
            "Epoch [1/10]. Loss: 0.135. Acc: 0.924 F1-score: 0.331. Test loss: 0.134. Test acc: 0.952. Test F1_score: 0.567. Recall: 0.449\n",
            "Epoch [2/10]. Loss: 0.130. Acc: 0.957 F1-score: 0.622. Test loss: 0.075. Test acc: 0.954. Test F1_score: 0.581. Recall: 0.455\n",
            "Epoch [3/10]. Loss: 0.100. Acc: 0.964 F1-score: 0.700. Test loss: 0.190. Test acc: 0.953. Test F1_score: 0.598. Recall: 0.496\n",
            "Epoch [4/10]. Loss: 0.105. Acc: 0.969 F1-score: 0.752. Test loss: 0.146. Test acc: 0.950. Test F1_score: 0.619. Recall: 0.580\n",
            "Epoch [5/10]. Loss: 0.068. Acc: 0.973 F1-score: 0.787. Test loss: 0.096. Test acc: 0.952. Test F1_score: 0.621. Recall: 0.560\n",
            "Epoch [6/10]. Loss: 0.085. Acc: 0.976 F1-score: 0.820. Test loss: 0.131. Test acc: 0.952. Test F1_score: 0.606. Recall: 0.531\n",
            "Epoch [7/10]. Loss: 0.053. Acc: 0.979 F1-score: 0.841. Test loss: 0.344. Test acc: 0.954. Test F1_score: 0.599. Recall: 0.491\n",
            "Epoch [8/10]. Loss: 0.071. Acc: 0.981 F1-score: 0.856. Test loss: 0.099. Test acc: 0.950. Test F1_score: 0.608. Recall: 0.558\n",
            "Epoch [9/10]. Loss: 0.066. Acc: 0.982 F1-score: 0.869. Test loss: 0.201. Test acc: 0.948. Test F1_score: 0.610. Recall: 0.576\n",
            "Epoch [10/10]. Loss: 0.040. Acc: 0.983 F1-score: 0.871. Test loss: 0.243. Test acc: 0.948. Test F1_score: 0.617. Recall: 0.596\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6173410404624278"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В целом мы также наблюдаем быстрое переобучение модели. Вероятно из-за малого количества обучающих примеров. Всё таки сильная несбалансированность классов влияет на результаты.\n",
        "\n",
        "И в принципе, тесты запускались несколько раз для разных моделей и отличия были минимальны и в разных запусках разные параметры давали чуть лучшие результаты. Пожалуй чаще всего на GRU требовался шаг обучения больше, чем на LSTM. \n",
        "\n",
        "Всё таки низкая сложность задачи и несбалансированность классов не позволяют вообще найти сильных различий между обучением разными моделями. Даже одномерные свёртки дают очень близкий результат.\n",
        "\n",
        "При этом по метрике Recall получилось добиться максимума на LSTM. И вообще рекурентные сети по этой метрике всё таки давали лучшие результаты, чем одномерные свёрточные сети."
      ],
      "metadata": {
        "id": "Z812YN_dDwV7"
      }
    }
  ]
}